{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d53d4c2",
   "metadata": {
    "id": "4d53d4c2"
   },
   "source": [
    "# Tâche 3 : Question-réponse avec GPT‑2 avec poursuite du pré-entraînement sur un corpus de Sherlock Holmes\n",
    "\n",
    "**Objectifs**\n",
    "\n",
    "Évaluer la qualité des réponses d’un modèle de langage **pré‑entraîné** (version **GPT-2 Medium (355M)** sur Hugging Face) lorsqu’on lui pose des questions sur un sujet vu au pré-entraînement.\n",
    "Dans ce *notebook*, vous poursuivez le pré-entraînement du modèle avec des textes de l'univers de *Sherlock Holmes*.  Comme pour la tâche 2, on doit construire un *prompt* minimal, générer des réponses avec le nouveau modèle, et évaluer la pertinence des résultats. Plusieurs de ces fonctions sont rendues disponibles.\n",
    "\n",
    "**Objectifs d’apprentissage**\n",
    "1. Poursuivre le préentraînement d'un modèle pré‑entraîné (Hugging Face) sur un corpus de taille moyenne.\n",
    "2. Comprendre et expliquer les **limites et apports du pré‑entraînement** sur des textes pertinents au domaine des questions.\n",
    "\n",
    "Tout comme pour la tâche 2, les **questions** pour évaluer le modèle vous sont fournies. Vous devez comprendre le format des questions chargées en mémoire. La **liste de livres** à utiliser pour le pré-entraînement et la **fonction** pour les monter en mémoire sont également disponibles. \n",
    "\n",
    "NOTE: Il est important de sauvegarder le modèle pré-entraîné dans cette tâche (ainsi que son tokenizer) car nous les réutilisons pour la tâche 4. \n",
    "\n",
    "> Il est recommandé de faire ce travail pratique en utilisant une carte graphique GPU compatible avec HuggingFace/Pytorch.\n",
    "> Si votre machine n’en possède pas, vous pouvez utiliser **Google Colab** pour exécuter le *notebook* dans le cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81af0ea3655c4578",
   "metadata": {
    "id": "81af0ea3655c4578"
   },
   "source": [
    "Si nécessaire, installer les *packages* suivant. Si vous exécutez sur Code Colab, ces *packages* devraient déjà être installés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P1jvDsOV7WVW",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T01:16:43.735114Z",
     "start_time": "2025-10-09T01:16:43.721585Z"
    },
    "id": "P1jvDsOV7WVW"
   },
   "outputs": [],
   "source": [
    "#!pip install datasets\n",
    "#!pip install accelerate\n",
    "#!pip install 'transformers[torch]'\n",
    "#!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d460d1d84efc873",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T01:16:43.969814Z",
     "start_time": "2025-10-09T01:16:43.965774Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 5 # il est possible d'ajuster la taille de batch. Les valeurs actuelles utilisent environ 10 Gb\n",
    "max_length = 256 # on réduit le contexte pour sauver du temps, nos exemples ne nécessite pas un plus grand contexte\n",
    "model_name = \"gpt2-medium\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660a299e09c87174",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T01:16:55.143183Z",
     "start_time": "2025-10-09T01:16:44.018837Z"
    },
    "id": "660a299e09c87174"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import pipeline, Trainer \n",
    "import os\n",
    "import json\n",
    "\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d5ba36",
   "metadata": {},
   "source": [
    "## 1. Chargement du modèle Hugging Face et du tokenizer (à compléter)\n",
    "\n",
    "Complétez le corps de la fonction `load_model(model_path)` afin qu’elle :\n",
    "\n",
    "- charge le **tokenizer** et le **modèle** Hugging Face à partir du chemin `model_path`.\n",
    "- **retourne** le tokenizer comme **première valeur de retour** et le modèle comme **seconde valeur de retour**.\n",
    "\n",
    "On ajoute également des fonctions pour monter les questions en mémoire et pour sauvegarder les réponses dans un fichier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a6b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    tokenizer = None  # TODO\n",
    "    model = None  # TODO\n",
    "    \n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c56a1e65ebeb313",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T01:16:55.164694Z",
     "start_time": "2025-10-09T01:16:55.156561Z"
    },
    "id": "4c56a1e65ebeb313"
   },
   "outputs": [],
   "source": [
    "def load_entries(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(f\"Question file must contain a list of objects. Got: {type(data)}\")\n",
    "    return data\n",
    "\n",
    "def save_answers(questions_answers, output_dir, out_file_name, display=True):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with open(os.path.join(output_dir, out_file_name), \"w\", encoding=\"utf-8\") as out:\n",
    "        for index, question, answer, expected_answer in questions_answers:\n",
    "            out.write(f\"Q: {question}\\nA: {answer}\\nExpected:{expected_answer}\\n{'-' * 60}\\n\")\n",
    "            if display:\n",
    "                print(f\"Q{index}: {question}\\nA: {answer}\\nExpected:{expected_answer}\\n{'-' * 60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc746173",
   "metadata": {},
   "source": [
    "## 2. Fonctions de test question-réponse  (à compléter)\n",
    "\n",
    "La fonction **test_on_questions** est utilisée pour parcourir **toutes les entrées** du fichier de questions afin de produire des réponses générées par le modèle.\n",
    "\n",
    "La génération d'une réponse à une question implique les étapes suivantes (fonction **process_entry** à compléter) : \n",
    "* Construire un prompt à l’aide de la fonction **build_prompt** (rendu disponible).\n",
    "* Utiliser le modèle (via un pipeline de génération de texte passé en argument) pour générer une réponse à une question.\n",
    "* Retourner la réponse générée par le modèle.  \n",
    "\n",
    "Points importants à souligner: \n",
    "* La fonction *process_entry* doit retourner uniquement la réponse générée par le modèle (sans le prompt).\n",
    "* Il est de votre responsabililté de choisir **les paramètres** du générateur (max_new_tokens, do_sample, temperature, top_k ou top_p). Décrivez ceux que vous avez retenus.\n",
    "\n",
    "> Afin de simplifier le travail, nous avons choisi de ne pas utiliser de *batchs* dans la fonction qui teste les questions.\n",
    "> Vous n'avez pas à prendre en compte le *warning* qui suggère d'utiliser des *datasets*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee0ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(entry):\n",
    "    return entry.get(\"question\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc8d736",
   "metadata": {},
   "source": [
    "Description des paramètres de génération: \n",
    "(à compléter...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83653b6bd010065",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T01:16:55.183765Z",
     "start_time": "2025-10-09T01:16:55.175733Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_entry(entry, prompt_builder, generator):\n",
    "    answer = None  # TODO\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b457b86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_questions(prompt_builder, model_path, question_file, out_file_name, output_dir=\"results\"):\n",
    "    entries = load_entries(question_file)\n",
    "    tokenizer, model = load_model(model_path)\n",
    "    generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "    results = []\n",
    "    for i, entry in enumerate(entries):\n",
    "        answer = process_entry(entry, prompt_builder, generator)\n",
    "        question = entry.get(\"question\", \"\")\n",
    "        expected_answer = entry.get(\"answer\", \"\")\n",
    "        results.append((i, question, answer, expected_answer))\n",
    "    save_answers(results, output_dir, out_file_name, display=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c70fe96",
   "metadata": {},
   "source": [
    "## 3. Poursuite du pré-entraînement du modèle GPT-2 (à compléter)\n",
    "\n",
    "Complétez le code suivant afin de poursuivre le préentraînement de GPT2 sur des textes de *Sherlock Holmes*.\n",
    "\n",
    "Les étapes à suivre sont de :\n",
    "* Télécharger le contenu des livres (on rend la fonction disponible)\n",
    "* Créer un *dataset* (version Hugging Face) d'entraînement à partir de ce contenu\n",
    "* Tokeniser ce *dataset*\n",
    "* Faire le pré-entraînement du modèle sur le *dataset* avec la classe ***Trainer*** de Hugging Face\n",
    "* Faire la sauvegarde du nouveau modèle dans un répertoire (voir *model_path*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b14a6bcc8ee527",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T01:16:59.580570Z",
     "start_time": "2025-10-09T01:16:55.197091Z"
    }
   },
   "outputs": [],
   "source": [
    "books = {\n",
    "    \"The Sign of the Four\": \"https://www.gutenberg.org/files/2097/2097-0.txt\",\n",
    "    \"The Adventures of Sherlock Holmes\": \"https://www.gutenberg.org/files/1661/1661-0.txt\",\n",
    "    \"The Memoirs of Sherlock Holmes\": \"https://www.gutenberg.org/files/834/834-0.txt\",\n",
    "    \"The Hound of the Baskervilles\": \"https://www.gutenberg.org/files/2852/2852-0.txt\",\n",
    "    \"His Last Bow\": \"https://www.gutenberg.org/files/2350/2350-0.txt\",\n",
    "    \"The Case-Book of Sherlock Holmes\": \"https://www.gutenberg.org/files/221/221-0.txt\"\n",
    "}\n",
    "\n",
    "def download_sherlock_dataset(books_to_process):\n",
    "    data = []\n",
    "\n",
    "    for title, url in books_to_process.items():\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            text = response.text\n",
    "\n",
    "            # Cette expression est plus robuste que ce qui était attendu dans le premier travail pratique\n",
    "            header_regex = r\"(?s)^.*?\\*{3}\\s*START OF\\b.*?\\r?\\n?\\*{3}\\s*\\r?\\n\"\n",
    "            header_pattern = re.compile(header_regex, flags=0)\n",
    "            clean_text = header_pattern.sub(\"\", text)\n",
    "\n",
    "            toc_regex = r\"(?ims)^\\s*contents\\s*$.*?^\\s*$\"\n",
    "            toc_pattern = re.compile(toc_regex, flags=0)\n",
    "            clean_text = toc_pattern.sub(\"\", clean_text)\n",
    "\n",
    "            regex_license_llm = r\"(?im)^\\s*\\*{3} END OF\\b.*[\\s\\S]*\\Z\"\n",
    "            license_llm_pattern = re.compile(regex_license_llm, flags=0)\n",
    "            clean_text = license_llm_pattern.sub(\"\", clean_text)\n",
    "\n",
    "            # To make it simpler to learn text without learning new lines\n",
    "            clean_text = re.sub(r\"\\r\\n\\r\\n\", \"\\n\", clean_text)\n",
    "            clean_text = re.sub(r\"\\r\\n\", \" \", clean_text)\n",
    "\n",
    "            data.append(clean_text)\n",
    "            print(f\"Downloaded: {title}\")\n",
    "        else:\n",
    "            print(f\"Failed to download: {title}\")\n",
    "\n",
    "    return \"\\n\".join(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3938df",
   "metadata": {},
   "source": [
    "Création du *dataset* d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ffcebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sherlock_text = download_sherlock_dataset(books_to_process=books)\n",
    "\n",
    "sherlock_dataset = None  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a1e7a7",
   "metadata": {},
   "source": [
    "Tokénisation du *dataset* d'entraînement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1790b1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, model = load_model(model_name)\n",
    "\n",
    "tokenized_dataset = None  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5779a3e2",
   "metadata": {},
   "source": [
    "Ajouter dans les cellules suivantes le code dont vous avez besoin pour poursuivre le pré-entraînement du modèle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8792c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"gpt2-sherlock-lm\"  # Répertoire où sauvegarder le nouveau modèle et le tokenizer \n",
    "\n",
    "trainer = None  # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa0cf15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T01:46:46.257446Z",
     "start_time": "2025-10-09T01:16:59.657914Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1852bde0ee79493ba8adb5c6e80c0e26",
      "02d5730a3b824b9488ac965c8cf03975",
      "246410304692490a9c75f15cccad2ca7",
      "e49397f3a86c4a628484195f1c8f35e5",
      "1993b6bf7e8540ba960cd5a99dfacc02",
      "63855c1f3e434b5e912d16e9fcca3c7d",
      "0e00d0317d9e4fb595d9ffd116492957",
      "5c2556b64a7b4c6d999ccc5fd5095c55",
      "b8020e8db2f14c8ba90ec9f1a9ce25de",
      "7c18198369c04dd8ae24f9ac7eacc139",
      "cedc0966f194417d94db80646792daf8"
     ]
    },
    "id": "6fa0cf15",
    "outputId": "6ed78374-c1fb-4237-f37b-0a3947931113"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9efb4a",
   "metadata": {},
   "source": [
    "Pour conclure cette section, sauvegardez le nouveau modèle et le *tokenizer* afin de les réutiliser dans la tâche 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d73409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabd806c",
   "metadata": {},
   "source": [
    "## 4. Génération de réponses avec le nouveau modèle GPT-2\n",
    "\n",
    "Exécutez la cellule suivante pour générer les réponses aux questions avec le modèle que vous venez de pré-entraîner sur des textes de *Sherlock Holmes*.\n",
    "Le temps d’exécution devrait se situer entre **5 et 10 minutes** si vous utilisez **Google Colab** avec un GPU.\n",
    "\n",
    "Note : N'oubliez pas d'ajouter le fichier de réponses générées par le modèle (voir *out_file_name*) dans votre remise du travail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wA5PwWtdQvNE",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T01:54:40.206982Z",
     "start_time": "2025-10-09T01:46:46.318579Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wA5PwWtdQvNE",
    "outputId": "d61cf7c8-3927-48a6-a82e-8e52b0554716"
   },
   "outputs": [],
   "source": [
    "questions = \"data/questions_sherlock.json\"\n",
    "out_file_name = \"pretrained_gpt2_answers.txt\"\n",
    "\n",
    "results = test_on_questions(prompt_builder=build_prompt, model_path=model_path, question_file=questions, out_file_name=out_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d73c5cc",
   "metadata": {},
   "source": [
    "## 5. Analyse des résultats "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8e187a",
   "metadata": {},
   "source": [
    "### 5.1 Évaluation quantitative (à compléter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7a7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def remove_articles(text):\n",
    "    return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "def white_space_fix(text):\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "def remove_punc(text):\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def normalize_answer(s):\n",
    "    \"\"\"Mettre en minuscule et retirer la ponctuation, des déterminants and les espaces.\"\"\"\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d80fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_f1(ground_truth, prediction):\n",
    "    \"\"\"Normalise les 2 textes, trouve ce qu'il y a en commun et estime précision, rappel et F1.\"\"\"\n",
    "    prediction_tokens = normalize_answer(prediction).split()\n",
    "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec8ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_generation(results): \n",
    "    # TODO\n",
    "    return eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0044a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = evaluation_generation(results)\n",
    "print(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cfb4d1",
   "metadata": {},
   "source": [
    "**Question :** Que pensez-vous de cette évaluation ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecc9e77",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb1b717",
   "metadata": {},
   "source": [
    "## 5. Analyse qualitative (à faire)\n",
    "\n",
    "Rédigez **5 à 15 phrases** présentant vos observations et expliquant pourquoi, selon vous, le modèle fournit ce type de réponses.\n",
    "\n",
    "Vous pouvez ajouter des cellules au besoin. \n",
    "\n",
    "> Cette étape prépare le terrain pour la tâche 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f01e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c1affa",
   "metadata": {},
   "source": [
    "   "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02d5730a3b824b9488ac965c8cf03975": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63855c1f3e434b5e912d16e9fcca3c7d",
      "placeholder": "​",
      "style": "IPY_MODEL_0e00d0317d9e4fb595d9ffd116492957",
      "value": "Map: 100%"
     }
    },
    "0e00d0317d9e4fb595d9ffd116492957": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "177cb70e811744d9b807a50ab8906835": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bfd3a46cec604b58994c9445a3abd3b9",
      "placeholder": "​",
      "style": "IPY_MODEL_6fb270e11547433ea37333150983834d",
      "value": "Map: 100%"
     }
    },
    "1852bde0ee79493ba8adb5c6e80c0e26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_02d5730a3b824b9488ac965c8cf03975",
       "IPY_MODEL_246410304692490a9c75f15cccad2ca7",
       "IPY_MODEL_e49397f3a86c4a628484195f1c8f35e5"
      ],
      "layout": "IPY_MODEL_1993b6bf7e8540ba960cd5a99dfacc02"
     }
    },
    "1993b6bf7e8540ba960cd5a99dfacc02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21c87467c9c9485aa5f073ae5e2db788": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "246410304692490a9c75f15cccad2ca7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c2556b64a7b4c6d999ccc5fd5095c55",
      "max": 11055,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b8020e8db2f14c8ba90ec9f1a9ce25de",
      "value": 11055
     }
    },
    "5c2556b64a7b4c6d999ccc5fd5095c55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63855c1f3e434b5e912d16e9fcca3c7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64203e620c994f50bb50435f161d641b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6fb270e11547433ea37333150983834d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7c18198369c04dd8ae24f9ac7eacc139": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f97d6edeeb740899fd8b58879030fe4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4c6536d6c2945d7bc5387bc4ed7c8fa",
      "max": 52002,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_64203e620c994f50bb50435f161d641b",
      "value": 52002
     }
    },
    "879a8f1045ab4d77adaa992759dc7264": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21c87467c9c9485aa5f073ae5e2db788",
      "placeholder": "​",
      "style": "IPY_MODEL_f87b1e94bff249fd954354f5c80b91e8",
      "value": " 52002/52002 [01:11&lt;00:00, 1158.09 examples/s]"
     }
    },
    "9cf8f9c87d224dc0bdeaa9788b5d0880": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_177cb70e811744d9b807a50ab8906835",
       "IPY_MODEL_7f97d6edeeb740899fd8b58879030fe4",
       "IPY_MODEL_879a8f1045ab4d77adaa992759dc7264"
      ],
      "layout": "IPY_MODEL_fe8e9dc94d174a79aa20a2121fe0dcd6"
     }
    },
    "b4c6536d6c2945d7bc5387bc4ed7c8fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8020e8db2f14c8ba90ec9f1a9ce25de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bfd3a46cec604b58994c9445a3abd3b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cedc0966f194417d94db80646792daf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e49397f3a86c4a628484195f1c8f35e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c18198369c04dd8ae24f9ac7eacc139",
      "placeholder": "​",
      "style": "IPY_MODEL_cedc0966f194417d94db80646792daf8",
      "value": " 11055/11055 [00:06&lt;00:00, 1944.70 examples/s]"
     }
    },
    "f87b1e94bff249fd954354f5c80b91e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe8e9dc94d174a79aa20a2121fe0dcd6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
