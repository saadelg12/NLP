{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4d53d4c2",
      "metadata": {
        "id": "4d53d4c2"
      },
      "source": [
        "# Tâche 3 : Question-réponse avec GPT‑2 avec poursuite du pré-entraînement sur un corpus de Sherlock Holmes\n",
        "\n",
        "**Objectifs**\n",
        "\n",
        "Évaluer la qualité des réponses d’un modèle de langage **pré‑entraîné** (version **GPT-2 Medium (355M)** sur Hugging Face) lorsqu’on lui pose des questions sur un sujet vu au pré-entraînement.\n",
        "Dans ce *notebook*, vous poursuivez le pré-entraînement du modèle avec des textes de l'univers de *Sherlock Holmes*.  Comme pour la tâche 2, on doit construire un *prompt* minimal, générer des réponses avec le nouveau modèle, et évaluer la pertinence des résultats. Plusieurs de ces fonctions sont rendues disponibles.\n",
        "\n",
        "**Objectifs d’apprentissage**\n",
        "1. Poursuivre le préentraînement d'un modèle pré‑entraîné (Hugging Face) sur un corpus de taille moyenne.\n",
        "2. Comprendre et expliquer les **limites et apports du pré‑entraînement** sur des textes pertinents au domaine des questions.\n",
        "\n",
        "Tout comme pour la tâche 2, les **questions** pour évaluer le modèle vous sont fournies. Vous devez comprendre le format des questions chargées en mémoire. La **liste de livres** à utiliser pour le pré-entraînement et la **fonction** pour les monter en mémoire sont également disponibles.\n",
        "\n",
        "NOTE: Il est important de sauvegarder le modèle pré-entraîné dans cette tâche (ainsi que son tokenizer) car nous les réutilisons pour la tâche 4.\n",
        "\n",
        "> Il est recommandé de faire ce travail pratique en utilisant une carte graphique GPU compatible avec HuggingFace/Pytorch.\n",
        "> Si votre machine n’en possède pas, vous pouvez utiliser **Google Colab** pour exécuter le *notebook* dans le cloud."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81af0ea3655c4578",
      "metadata": {
        "id": "81af0ea3655c4578"
      },
      "source": [
        "Si nécessaire, installer les *packages* suivant. Si vous exécutez sur Code Colab, ces *packages* devraient déjà être installés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P1jvDsOV7WVW",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-09T01:16:43.735114Z",
          "start_time": "2025-10-09T01:16:43.721585Z"
        },
        "id": "P1jvDsOV7WVW"
      },
      "outputs": [],
      "source": [
        "#!pip install datasets\n",
        "#!pip install accelerate\n",
        "#!pip install 'transformers[torch]'\n",
        "#!pip3 install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d460d1d84efc873",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-09T01:16:43.969814Z",
          "start_time": "2025-10-09T01:16:43.965774Z"
        },
        "id": "4d460d1d84efc873"
      },
      "outputs": [],
      "source": [
        "batch_size = 5 # il est possible d'ajuster la taille de batch. Les valeurs actuelles utilisent environ 10 Gb\n",
        "max_length = 256 # on réduit le contexte pour sauver du temps, nos exemples ne nécessite pas un plus grand contexte\n",
        "model_name = \"gpt2-medium\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "660a299e09c87174",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-09T01:16:55.143183Z",
          "start_time": "2025-10-09T01:16:44.018837Z"
        },
        "id": "660a299e09c87174"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from transformers import pipeline, Trainer\n",
        "import os\n",
        "import json\n",
        "\n",
        "import re\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0d5ba36",
      "metadata": {
        "id": "a0d5ba36"
      },
      "source": [
        "## 1. Chargement du modèle Hugging Face et du tokenizer (à compléter)\n",
        "\n",
        "Complétez le corps de la fonction `load_model(model_path)` afin qu’elle :\n",
        "\n",
        "- charge le **tokenizer** et le **modèle** Hugging Face à partir du chemin `model_path`.\n",
        "- **retourne** le tokenizer comme **première valeur de retour** et le modèle comme **seconde valeur de retour**.\n",
        "\n",
        "On ajoute également des fonctions pour monter les questions en mémoire et pour sauvegarder les réponses dans un fichier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54a6b2f6",
      "metadata": {
        "id": "54a6b2f6"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "def load_model(model_path):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "\n",
        "    # GPT-2 n'en a pas par défaut\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        model.config.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "    return tokenizer, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c56a1e65ebeb313",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-09T01:16:55.164694Z",
          "start_time": "2025-10-09T01:16:55.156561Z"
        },
        "id": "4c56a1e65ebeb313"
      },
      "outputs": [],
      "source": [
        "def load_entries(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "    if not isinstance(data, list):\n",
        "        raise ValueError(f\"Question file must contain a list of objects. Got: {type(data)}\")\n",
        "    return data\n",
        "\n",
        "def save_answers(questions_answers, output_dir, out_file_name, display=True):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    with open(os.path.join(output_dir, out_file_name), \"w\", encoding=\"utf-8\") as out:\n",
        "        for index, question, answer, expected_answer in questions_answers:\n",
        "            out.write(f\"Q: {question}\\nA: {answer}\\nExpected:{expected_answer}\\n{'-' * 60}\\n\")\n",
        "            if display:\n",
        "                print(f\"Q{index}: {question}\\nA: {answer}\\nExpected:{expected_answer}\\n{'-' * 60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc746173",
      "metadata": {
        "id": "bc746173"
      },
      "source": [
        "## 2. Fonctions de test question-réponse  (à compléter)\n",
        "\n",
        "La fonction **test_on_questions** est utilisée pour parcourir **toutes les entrées** du fichier de questions afin de produire des réponses générées par le modèle.\n",
        "\n",
        "La génération d'une réponse à une question implique les étapes suivantes (fonction **process_entry** à compléter) :\n",
        "* Construire un prompt à l’aide de la fonction **build_prompt** (rendu disponible).\n",
        "* Utiliser le modèle (via un pipeline de génération de texte passé en argument) pour générer une réponse à une question.\n",
        "* Retourner la réponse générée par le modèle.  \n",
        "\n",
        "Points importants à souligner:\n",
        "* La fonction *process_entry* doit retourner uniquement la réponse générée par le modèle (sans le prompt).\n",
        "* Il est de votre responsabililté de choisir **les paramètres** du générateur (max_new_tokens, do_sample, temperature, top_k ou top_p). Décrivez ceux que vous avez retenus.\n",
        "\n",
        "> Afin de simplifier le travail, nous avons choisi de ne pas utiliser de *batchs* dans la fonction qui teste les questions.\n",
        "> Vous n'avez pas à prendre en compte le *warning* qui suggère d'utiliser des *datasets*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69ee0ec8",
      "metadata": {
        "id": "69ee0ec8"
      },
      "outputs": [],
      "source": [
        "def build_prompt(entry):\n",
        "    return entry.get(\"question\", \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fc8d736",
      "metadata": {
        "id": "9fc8d736"
      },
      "source": [
        "### Description des paramètres de génération:\n",
        "- **max_new_tokens=100** : Limite la longueur de la réponse à 100 tokens pour éviter des réponses trop longues\n",
        "- **do_sample=True** : Active l'échantillonnage probabiliste pour des réponses plus variées et naturelles\n",
        "- **temperature=0.7** : Contrôle la créativité (0.7 offre un bon équilibre entre cohérence et diversité)\n",
        "- **top_p=0.9** : Considère les tokens dont la probabilité cumulative atteint 90%\n",
        "- **top_k=100**: Limite la sélection aux 100 tokens les plus probables à chaque étape\n",
        "- **pad_token_id** : Nécessaire pour éviter les warnings avec GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83653b6bd010065",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-09T01:16:55.183765Z",
          "start_time": "2025-10-09T01:16:55.175733Z"
        },
        "id": "83653b6bd010065"
      },
      "outputs": [],
      "source": [
        "def process_entry(entry, prompt_builder, generator):\n",
        "    # Construit le prompt à partir de l'entrée\n",
        "    prompt = prompt_builder(entry)\n",
        "\n",
        "    # Génére la réponse avec le modèle\n",
        "    result = generator(\n",
        "        prompt,\n",
        "        max_new_tokens=100,       # Longueur maximale de la réponse\n",
        "        do_sample=True,           # Active l'échantillonnage probabiliste\n",
        "        temperature=0.7,          # Contrôle la créativité\n",
        "        top_p=0.9,                # Échantillonnage nucleus\n",
        "        top_k=100,                # Échantillonnage top-k\n",
        "        pad_token_id=generator.tokenizer.eos_token_id  # Évite les warnings\n",
        "    )\n",
        "\n",
        "    # Extrait le texte généré complet\n",
        "    generated_text = result[0]['generated_text']\n",
        "\n",
        "    # Retourne uniquement la réponse (enleve le prompt)\n",
        "    answer = generated_text[len(prompt):].strip()\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b457b86d",
      "metadata": {
        "id": "b457b86d"
      },
      "outputs": [],
      "source": [
        "def test_on_questions(prompt_builder, model_path, question_file, out_file_name, output_dir=\"results\"):\n",
        "    entries = load_entries(question_file)\n",
        "    tokenizer, model = load_model(model_path)\n",
        "    generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "    results = []\n",
        "    for i, entry in enumerate(entries):\n",
        "        answer = process_entry(entry, prompt_builder, generator)\n",
        "        question = entry.get(\"question\", \"\")\n",
        "        expected_answer = entry.get(\"answer\", \"\")\n",
        "        results.append((i, question, answer, expected_answer))\n",
        "    save_answers(results, output_dir, out_file_name, display=True)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c70fe96",
      "metadata": {
        "id": "6c70fe96"
      },
      "source": [
        "## 3. Poursuite du pré-entraînement du modèle GPT-2 (à compléter)\n",
        "\n",
        "Complétez le code suivant afin de poursuivre le préentraînement de GPT2 sur des textes de *Sherlock Holmes*.\n",
        "\n",
        "Les étapes à suivre sont de :\n",
        "* Télécharger le contenu des livres (on rend la fonction disponible)\n",
        "* Créer un *dataset* (version Hugging Face) d'entraînement à partir de ce contenu\n",
        "* Tokeniser ce *dataset*\n",
        "* Faire le pré-entraînement du modèle sur le *dataset* avec la classe ***Trainer*** de Hugging Face\n",
        "* Faire la sauvegarde du nouveau modèle dans un répertoire (voir *model_path*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67b14a6bcc8ee527",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-09T01:16:59.580570Z",
          "start_time": "2025-10-09T01:16:55.197091Z"
        },
        "id": "67b14a6bcc8ee527"
      },
      "outputs": [],
      "source": [
        "books = {\n",
        "    \"The Sign of the Four\": \"https://www.gutenberg.org/files/2097/2097-0.txt\",\n",
        "    \"The Adventures of Sherlock Holmes\": \"https://www.gutenberg.org/files/1661/1661-0.txt\",\n",
        "    \"The Memoirs of Sherlock Holmes\": \"https://www.gutenberg.org/files/834/834-0.txt\",\n",
        "    \"The Hound of the Baskervilles\": \"https://www.gutenberg.org/files/2852/2852-0.txt\",\n",
        "    \"His Last Bow\": \"https://www.gutenberg.org/files/2350/2350-0.txt\",\n",
        "    \"The Case-Book of Sherlock Holmes\": \"https://www.gutenberg.org/files/221/221-0.txt\"\n",
        "}\n",
        "\n",
        "def download_sherlock_dataset(books_to_process):\n",
        "    data = []\n",
        "\n",
        "    for title, url in books_to_process.items():\n",
        "        response = requests.get(url)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            text = response.text\n",
        "\n",
        "            # Cette expression est plus robuste que ce qui était attendu dans le premier travail pratique\n",
        "            header_regex = r\"(?s)^.*?\\*{3}\\s*START OF\\b.*?\\r?\\n?\\*{3}\\s*\\r?\\n\"\n",
        "            header_pattern = re.compile(header_regex, flags=0)\n",
        "            clean_text = header_pattern.sub(\"\", text)\n",
        "\n",
        "            toc_regex = r\"(?ims)^\\s*contents\\s*$.*?^\\s*$\"\n",
        "            toc_pattern = re.compile(toc_regex, flags=0)\n",
        "            clean_text = toc_pattern.sub(\"\", clean_text)\n",
        "\n",
        "            regex_license_llm = r\"(?im)^\\s*\\*{3} END OF\\b.*[\\s\\S]*\\Z\"\n",
        "            license_llm_pattern = re.compile(regex_license_llm, flags=0)\n",
        "            clean_text = license_llm_pattern.sub(\"\", clean_text)\n",
        "\n",
        "            # To make it simpler to learn text without learning new lines\n",
        "            clean_text = re.sub(r\"\\r\\n\\r\\n\", \"\\n\", clean_text)\n",
        "            clean_text = re.sub(r\"\\r\\n\", \" \", clean_text)\n",
        "\n",
        "            data.append(clean_text)\n",
        "            print(f\"Downloaded: {title}\")\n",
        "        else:\n",
        "            print(f\"Failed to download: {title}\")\n",
        "\n",
        "    return \"\\n\".join(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e3938df",
      "metadata": {
        "id": "9e3938df"
      },
      "source": [
        "Création du *dataset* d'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87ffcebd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87ffcebd",
        "outputId": "4ecc343c-d987-4989-ab6e-70445f6f7036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: The Sign of the Four\n",
            "Downloaded: The Adventures of Sherlock Holmes\n",
            "Downloaded: The Memoirs of Sherlock Holmes\n",
            "Downloaded: The Hound of the Baskervilles\n",
            "Downloaded: His Last Bow\n",
            "Downloaded: The Case-Book of Sherlock Holmes\n",
            "Nombre de lignes dans le dataset : 11052\n"
          ]
        }
      ],
      "source": [
        "sherlock_text = download_sherlock_dataset(books_to_process=books)\n",
        "text_lines = [line.strip() for line in sherlock_text.split('\\n') if line.strip()]\n",
        "\n",
        "\n",
        "from datasets import Dataset\n",
        "sherlock_dataset = Dataset.from_dict({\"text\": text_lines})\n",
        "print(f\"Nombre de lignes dans le dataset : {len(sherlock_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9a1e7a7",
      "metadata": {
        "id": "b9a1e7a7"
      },
      "source": [
        "Tokénisation du *dataset* d'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1790b1cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152,
          "referenced_widgets": [
            "a2ab8cc6f4d34c92b0be69ab2c472bc6",
            "2058c2dc452644d09eac9543c1cd2744",
            "c73a79ff61564dc290056ba84384b733",
            "9fa1c2bc8694422e87a307a3fb6dc874",
            "75eb4886cd41410295f431fe81e718fc",
            "91d0252492c748c1bbe9b53c87e0d647",
            "7c78590ef1444f1990a81eeb1ba8b698",
            "3af8a83391534831bdb2711a5d8c1001",
            "5d817a17974b43b98d0f20e94eeffb91",
            "5e07de7308ad4d1eab1572dd1b59bfa5",
            "08f9d6970c7d466d9aff1a0095e76d16",
            "77ede7036bb64f998de06aa93e2ffc5c",
            "9175319774a14bdc8a7618addfcf3135",
            "ce352f88d39044fb8d398de87dc3aba8",
            "b887f9ee04934970a8565f696bbd1af1",
            "880851fe0dc54d04b541548a402bda36",
            "34dce65d31a84dc3b051f80f9ef6b6af",
            "c4d6263e3306473ea5c5935ac9f91457",
            "df7e767ee4f84f30be23f2af183a3523",
            "fb9ae1e3a09e4d7d9e7b2cdbbde60b61",
            "7be790e8a28f422482561b9f3c852226",
            "e81e30ec2ca14f518fe040314b5c9aac"
          ]
        },
        "id": "1790b1cc",
        "outputId": "7cbd4829-2fd4-4ef0-9443-1b829eaadd42"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11052 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2ab8cc6f4d34c92b0be69ab2c472bc6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11052 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77ede7036bb64f998de06aa93e2ffc5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre d'exemples après regroupement : 2737\n",
            "Taille de chaque bloc : 256 tokens\n"
          ]
        }
      ],
      "source": [
        "tokenizer, model = load_model(model_name)\n",
        "\n",
        "# 1) Tokenisation\n",
        "def tokenize_fn(batch):\n",
        "    return tokenizer(\n",
        "        batch[\"text\"],\n",
        "        add_special_tokens=False,\n",
        "        return_attention_mask=False,  # évite la colonne attention_mask\n",
        "    )\n",
        "\n",
        "tokenized = sherlock_dataset.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "# 2) Regroupement en blocs\n",
        "block_size = max_length\n",
        "def group_texts(examples):\n",
        "    \"\"\"Concatène tous les tokens et les regroupe en blocs de taille block_size\"\"\"\n",
        "    ids = sum(examples[\"input_ids\"], [])\n",
        "    total = (len(ids) // block_size) * block_size # Nombre total de tokens utilisables\n",
        "    input_ids = [ids[i:i+block_size] for i in range(0, total, block_size)]\n",
        "    return {\"input_ids\": input_ids, \"labels\": input_ids}\n",
        "\n",
        "tokenized_dataset = tokenized.map(group_texts, batched=True)\n",
        "print(f\"Nombre d'exemples après regroupement : {len(tokenized_dataset)}\")\n",
        "print(f\"Taille de chaque bloc : {block_size} tokens\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5779a3e2",
      "metadata": {
        "id": "5779a3e2"
      },
      "source": [
        "Ajouter dans les cellules suivantes le code dont vous avez besoin pour poursuivre le pré-entraînement du modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8792c5a4",
      "metadata": {
        "id": "8792c5a4"
      },
      "outputs": [],
      "source": [
        "model_path = \"gpt2-sherlock-lm\"  # Répertoire où sauvegarder le nouveau modèle et le tokenizer\n",
        "\n",
        "from transformers import DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
        "\n",
        "# collator causal LM (pas de MLM pour GPT-2)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "# Arguments d'entraînement\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_path,\n",
        "    overwrite_output_dir=True,\n",
        "    per_device_train_batch_size=batch_size,  # batch_size=5\n",
        "    num_train_epochs=3,       # Nombre d'époques d'entraînement\n",
        "    learning_rate=5e-5,       # Taux d'apprentissage\n",
        "    save_steps=500,           # Sauvegarde tous les 500 steps\n",
        "    logging_steps=100,        # Logge tous les 100 steps\n",
        "    fp16=True,                # Accélère l'entraînement\n",
        "    report_to=\"none\"          # Désactive wandb\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=data_collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fa0cf15",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-09T01:46:46.257446Z",
          "start_time": "2025-10-09T01:16:59.657914Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "6fa0cf15",
        "outputId": "ad54302e-03c6-4b26-f68c-c036fd0271c2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1644' max='1644' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1644/1644 16:55, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.909000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.787200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.713100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>2.664900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.657800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>2.540700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>2.424800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>2.414800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>2.406200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.398600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>2.414100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>2.271300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>2.269700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>2.262300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>2.236500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>2.285200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1644, training_loss=2.4718082084562947, metrics={'train_runtime': 1016.0095, 'train_samples_per_second': 8.082, 'train_steps_per_second': 1.618, 'total_flos': 3812780701384704.0, 'train_loss': 2.4718082084562947, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd9efb4a",
      "metadata": {
        "id": "dd9efb4a"
      },
      "source": [
        "Pour conclure cette section, sauvegardez le nouveau modèle et le *tokenizer* afin de les réutiliser dans la tâche 4.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d73409d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d73409d",
        "outputId": "47542384-dc22-492f-ad71-71c17e0f9463"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('gpt2-sherlock-lm/tokenizer_config.json',\n",
              " 'gpt2-sherlock-lm/special_tokens_map.json',\n",
              " 'gpt2-sherlock-lm/vocab.json',\n",
              " 'gpt2-sherlock-lm/merges.txt',\n",
              " 'gpt2-sherlock-lm/added_tokens.json',\n",
              " 'gpt2-sherlock-lm/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "trainer.save_model(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dabd806c",
      "metadata": {
        "id": "dabd806c"
      },
      "source": [
        "## 4. Génération de réponses avec le nouveau modèle GPT-2\n",
        "\n",
        "Exécutez la cellule suivante pour générer les réponses aux questions avec le modèle que vous venez de pré-entraîner sur des textes de *Sherlock Holmes*.\n",
        "Le temps d’exécution devrait se situer entre **5 et 10 minutes** si vous utilisez **Google Colab** avec un GPU.\n",
        "\n",
        "Note : N'oubliez pas d'ajouter le fichier de réponses générées par le modèle (voir *out_file_name*) dans votre remise du travail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wA5PwWtdQvNE",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-09T01:54:40.206982Z",
          "start_time": "2025-10-09T01:46:46.318579Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA5PwWtdQvNE",
        "outputId": "94d9027c-b803-47fe-cdec-b568fdc07cfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q0: Where do Sherlock Holmes and Dr. Watson live?\n",
            "A: ”“In a very old, very bad, very shabby little house called the Baker Street Station.”“And what do they do there?”“They get their information from the station-master and from the post-master.”“And how do they get their information?”“From the post-master.”“How did you get it?”“Well, I was walking round the corner on my\n",
            "Expected:221B Baker Street, London.\n",
            "------------------------------------------------------------\n",
            "Q1: Who is Sherlock Holmes' loyal friend and chronicler?\n",
            "A: ”“Well, he’s my friend, but I don’t know him very well. He is a little retiring, and I don’t know that he would want me to go out of my way to meet him.”“But you have never met him?”“I have not.”“Well, then, how do you know that he is a friend?”“Well, I have heard of him\n",
            "Expected:Dr. John H. Watson.\n",
            "------------------------------------------------------------\n",
            "Q2: Who is considered 'The Woman' by Sherlock Holmes?\n",
            "A: ”“My dear fellow, there are many, many       who know her intimately. She is a very remarkable woman, and       I have never met a more remarkable woman. She is a woman of       extraordinary strength, and of extraordinary intelligence. She is       of a fine, alert, and expressive countenance, and she is       one of the very few women\n",
            "Expected:Irene Adler.\n",
            "------------------------------------------------------------\n",
            "Q3: Which story features the Red-Headed League?\n",
            "A: ”“The very worst that ever was done in the county.”“You are not joking, then?”“I am.”“How do you know that?”“Because I was there when the lady was arrested.”“So I was. And yet, if you will be so good as to go down to the station, I shall be happy to look into this matter.”“But I cannot do\n",
            "Expected:The Adventure of the Red-Headed League.\n",
            "------------------------------------------------------------\n",
            "Q4: What is the primary occupation of Sherlock Holmes?\n",
            "A: ”“I am a professor of criminology at the University of London.”“But how long have you been a professor?”“I have been a lecturer for five years, and my first ten years were devoted entirely to the study of crime.”“How long have you been an active member of the faculty?”“I have been a member since I was a lecturer, and have acted as secretary for seven years.”\n",
            "Expected:Consulting detective.\n",
            "------------------------------------------------------------\n",
            "Q5: Who is Sherlock Holmes' arch-nemesis?\n",
            "A: ”“That is a very good question. I cannot say. I should say that it is a question which I have often wished to ask myself, and that I am continually on the verge of discovering the answers to it.”“But how?”“I cannot tell you. It is so vague, and yet so certain, that I cannot help thinking that it may be of some help to me.”“And how?”“I\n",
            "Expected:Professor James Moriarty.\n",
            "------------------------------------------------------------\n",
            "Q6: What musical instrument does Sherlock Holmes play?\n",
            "A: ”“I play a violin.”“But he can play a harp, and you can play a harp, and he can play a harp, and you can play a harp, and he can play a harp, and you can play a harp, and he can play a harp, and you can play a harp, and he can play a harp, and you can play a harp, and he can play a harp\n",
            "Expected:The violin.\n",
            "------------------------------------------------------------\n",
            "Q7: What is the name of Sherlock Holmes' elder brother?\n",
            "A: ” I asked.“It is Jonathan. He is a very small, gentle-spoken man, but a gentleman. He has a very large estate, and he has given us a large sum.”“And why?”“Because we have been good enough to give him a large share of the property. He is a man of good character, and I am sure that you will be pleased to know that he has no grudge against us.”�\n",
            "Expected:Mycroft Holmes.\n",
            "------------------------------------------------------------\n",
            "Q8: What is the blue gemstone found inside a Christmas goose called?\n",
            "A: ”“It is a yellow one.”“And it is found in the same goose as the blue gem?”“Yes, it is.”“How can you be certain that it is the same one?”“Because it was not found in the same goose as the blue gem.”“You have no evidence?”“Not a shred of it.”“It is a fact!”\n",
            "Expected:The Blue Carbuncle.\n",
            "------------------------------------------------------------\n",
            "Q9: What residue does Holmes often analyze to identify smokers?\n",
            "A: ”“Possibly the smoke.”“Then I understand that the smoke of the cigarette is not a common material?”“No, it is not.”“But the cigar-ends are.”“No.”“The cigar-ends are a distinctively European material.”“But the cigar-ends are a common material?”“Certainly.”“And the tobacco?”\n",
            "Expected:Tobacco ash.\n",
            "------------------------------------------------------------\n",
            "Q10: What tactic besides observation does Holmes often use to gather information?\n",
            "A: ”“I think that I have already mentioned it. The fact is, Watson, that you are a man of little taste, and that you have a special faculty for picking out details. As I have said, your tastes are generally superficial. But this particular detail which I am interested in is very important. You will observe that it is not the size of the shoe, but the colour of the sole which is of importance.”“What colour?”“Well\n",
            "Expected:Disguise.\n",
            "------------------------------------------------------------\n",
            "Q11: What was the profession of Dr. John Watson?\n",
            "A: ”“He was a medical man,” said Holmes.“Was he ever a Freemason?”“No, he never was.”“Well, then, why should he be so anxious to know all about the Freemasons?”“I have no idea.”“Then it must be some mystery connected with Freemasonry.”“It is not so mysterious as you suppose. I have no doubt that you have\n",
            "Expected:Doctor.\n",
            "------------------------------------------------------------\n",
            "Q12: What kind of marks on the ground does Holmes often study to track people?\n",
            "A: ”“He does so, but seldom with the same intensity. In this case, I should say that he had no difficulty in tracing the man from the moment that he was seated.”“But how did he know that?”“Because his head was tilted so that the head of the man was facing the window. It is not a very common position, Watson, and yet this was it.”“That was the point, then, of the\n",
            "Expected:Footprints.\n",
            "------------------------------------------------------------\n",
            "Q13: Who is the landlady of 221B Baker Street?\n",
            "A: ”“Mrs. Brown, of 221B Baker Street.”“Yes, Mrs. Brown, the landlady of 221B Baker Street.”“Yes, you are right, I am glad to hear it.”“How is the kitchen?”“It is well cleaned, though it is rather late for the dinner.”“How is the dining-room?”“Very clean, sir.”\n",
            "Expected:Mrs. Hudson.\n",
            "------------------------------------------------------------\n",
            "Q14: What substance did Sherlock Holmes sometimes use to stimulate his mind?\n",
            "A: ”“I think that I have already given you an indication of the kind. I am indebted to you for a very interesting study of the art of deduction.”“I am indebted also to you for a very interesting study of the art of memory. You have, I am sure, some knowledge of the subject, and I am glad that you have taken the trouble to tell me all that you know.”“In the first place,” said I,\n",
            "Expected:Cocaine.\n",
            "------------------------------------------------------------\n",
            "Q15: Who is the Scotland Yard detective that often consults Holmes?\n",
            "A: ”“Well, I don’t know him,” said the old man, “but he is a very excellent detective. He is very good at his work.”“Well, how can you say that?”“Well, you’ll find that it is very difficult to prove that he is not.”“Well, well, then, you’ll find that it is also very difficult to prove that he is\n",
            "Expected:Inspector Lestrade (Gregson or Bradstreet also acceptable).\n",
            "------------------------------------------------------------\n",
            "Q16: What warning arrives as envelopes containing dried orange seeds?\n",
            "A: ”“It is a very common occurrence,” said Sherlock Holmes, laughing. “I have seen them in the back of the mail-bag of a lady who has been away from home for some weeks. It is the worst case of them all. I suppose that you have no objection to my having you both examined?”“I think that it is essential that I should have the information before I start.”“No, sir; I have no\n",
            "Expected:Five orange pips.\n",
            "------------------------------------------------------------\n",
            "Q17: What is the bog near Baskerville Hall called?\n",
            "A: ”“The bog at Baskerville Hall.”“And you have seen the same in every direction?”“Yes.”“You have no doubt, then, that it is the same place?”“No, I have not.”“But you have seen the same object?”“Yes.”“The object?”“The same.”“Then it must be\n",
            "Expected:The Grimpen Mire.\n",
            "------------------------------------------------------------\n",
            "Q18: Which London newspaper does Holmes frequently read?\n",
            "A: ”“Well, I suppose that the City-Journal of the Times?”“No, no.”“How about the Morning Chronicle of the City?”“I don’t know.”“Do you read any other papers?”“Not one.”“And you are a busy man?”“I have been for years.”“I am sure that you do.�\n",
            "Expected:The Times.\n",
            "------------------------------------------------------------\n",
            "Q19: What kind of drawings form the code that Holmes deciphers on walls and paper?\n",
            "A: ”“I suppose that I could tell you,” said he. “There are some of them, of course, that are of a peculiar character. I call them ‘débris-drawings’ because they are drawn up in a way which gives them the appearance of being torn or torn apart.’“Oh, yes, that is very interesting,” said I. “And yet they are of the same sort as those in which\n",
            "Expected:Dancing stick figures.\n",
            "------------------------------------------------------------\n",
            "Q20: What kind of jewel is set in the damaged coronet handled by a banker?\n",
            "A: ”“It is a fine emerald, very rare, and very valuable.”“And what was the banker’s name?”“It is unknown.”“How about the date?”“It was on the 7th of last month.”“Did you observe any change in the coronet?”“No, I have not.”“You are a careful man, are you not\n",
            "Expected:Beryls.\n",
            "------------------------------------------------------------\n",
            "Q21: What combat sport is Holmes proficient in?\n",
            "A: ”“In shooting.”“How about the fighting?”“Well, I've done it in the States, and I've been in the Crimean War.”“You're a professional.”“I am.”“Then let me ask you, in the first place, who you are and what you do?”“I am a private detective.”“And who are you?”�\n",
            "Expected:Boxing.\n",
            "------------------------------------------------------------\n",
            "Q22: What does Sherlock Holmes keep in his Persian slipper?\n",
            "A: ”“It is a case of a man who has been beaten so much that he is driven to suicide. His pockets are full of cash, and he is desperate for it. He has, as you may imagine, a dozen different methods of killing himself, and he is not content with one. He has, as you may imagine, a dozen different weapons, and he is not content with one. He has, as you may imagine, a dozen different ways of injuring himself, and\n",
            "Expected:Pipe tobacco.\n",
            "------------------------------------------------------------\n",
            "Q23: In which room at 221B do most client interviews happen?\n",
            "A: ”“Well, I don’t know. I have no idea.”“Then you must not know, for it is a secret which is to be kept.”“It is a very serious matter, and I would not have it known.”“Then you will tell me.”“Well, I must tell you. I have seen the gentleman who is to be interviewed. He is a gentleman of fifty. He is a\n",
            "Expected:The sitting-room.\n",
            "------------------------------------------------------------\n",
            "Q24: What important document goes missing from the Foreign Office in one case?\n",
            "A: ”“A note.”“A note?”“A note.”“What do you think of that?”“It is not very popular.”“Then we must take it.”“It is an essential part of our investigation. It may be the clue.”“It is not.”“But if it is so, it is essential. If we can only find out who\n",
            "Expected:A secret naval treaty.\n",
            "------------------------------------------------------------\n",
            "Q25: What hot drink is often served at Baker Street?\n",
            "A: ”“I have no doubt that it is the stout.”“Very well. I think that we must take our leave of the gentlemen, and I shall have the pleasure of addressing your name to in the morning.”“I shall be happy to oblige you,” said he, as we stepped out into the sunshine. “If you would be so good as to step into the cab with me I will give you a short sketch of the circumstances\n",
            "Expected:Tea.\n",
            "------------------------------------------------------------\n",
            "Q26: What object ties Irene Adler to a scandal with a European king?\n",
            "A: ”“I suppose that you are aware that there is a brother and sister of mine, and that they have a house in Norwood. They live at the present address.”“Well, you must have heard of them. They are very rich, and they have a considerable estate.”“Oh, yes; they have a great house.”“And a brother?”“Yes.”“Is there any connection between them\n",
            "Expected:A compromising photograph.\n",
            "------------------------------------------------------------\n",
            "Q27: What weapon does Dr. Watson often carry?\n",
            "A: ”“A revolver.”“You have not yet seen the revolver, then?”“No.”“Well, then, you are very much mistaken if you say that I have never seen it. I have seen it, and I have had occasion to examine it.”“I see. That is certainly a very remarkable statement. It is not to be taken as a mere statement of fact. It is an absolute and absolute denial.\n",
            "Expected:A revolver.\n",
            "------------------------------------------------------------\n",
            "Q28: In which country did Dr. Watson serve as an army doctor?\n",
            "A: ”“He was a Colonel of the South African Infantry.”“And how long did he serve in that regiment?”“Twenty-two years.”“Did he ever leave it?”“No; he was a faithful and devoted servant.”“He was a tall, thin, strong-looking man, and he had a very peculiar air of suavity and stoicism about him. He was never irritable,\n",
            "Expected:Afghanistan.\n",
            "------------------------------------------------------------\n",
            "Q29: What is the missing racehorse’s name in the Dartmoor case?\n",
            "A: ”“Pennyroyal.”“I am sorry to hear that. But I would not wish to take the trouble to inquire further.”“It is not the very difficult matter that we are dealing with,” said Holmes, with an amused twinkle in his eye. “I am sure that it is not very difficult, and yet I should like to hear the details.”“The horse,” said I, “\n",
            "Expected:Silver Blaze.\n",
            "------------------------------------------------------------\n",
            "Q30: What London vehicle do Holmes and Watson frequently hire for short trips?\n",
            "A: ”“Yes, sir, we are always a little late to the station.”“But why?”“Well, it is a pity, Mr. Holmes, that we have to wait. It would be better to drive.”“Why?”“Because you can see the station better from the road.”“I see. Well, then, if you could just go out with us to the station, we might be\n",
            "Expected:A hansom cab.\n",
            "------------------------------------------------------------\n",
            "Q31: In which English county do Holmes and Watson investigate a deadly household powder?\n",
            "A: ”“In Camberwell.”“Good! Then, Watson, you will step into my little box, and we shall begin our investigation.”The door of the study opened and two tall, dark, well-dressed men entered.“What can I do for you, Mr. Holmes?”“I have heard of your having a case of a different sort.”“That is what I want to hear. Come in,\n",
            "Expected:Cornwall.\n",
            "------------------------------------------------------------\n",
            "Q32: Where does Holmes retire?\n",
            "A: ”“I don’t know.”“When you are at home?”“No, I go to bed at nine.”“It is a great inconvenience to you, Watson, when you are away from home.”“But I am a good woman. I take it that you would not mind me doing so?”“Certainly not.”“Then I shall go and arrange my affairs.”\n",
            "Expected:Sussex Downs.\n",
            "------------------------------------------------------------\n",
            "Q33: What does Watson call Holmes’ method of reasoning?\n",
            "A: ”“It is to say that he is never satisfied until he has got it right.”“You think so?”“Yes, I do.”“You think that the reason why he never gets it right is because he is not himself a perfect thinker?”“Exactly.”“So he is always at a loss.”“Exactly.”“And yet it is his very nature to be in\n",
            "Expected:“The science of deduction and analysis.”\n",
            "------------------------------------------------------------\n",
            "Q34: What is the name of the street‑boy network Holmes employs?\n",
            "A: ”“A branch of the Street Directory,” said he.“What does the Street Directory mean?”“It is a list of every street in London, with the addresses of the houses which correspond to them.”“And this young man is a member of that network?”“Yes; he was the first to call.”“Have you any idea of his identity?”“No; I don’\n",
            "Expected:The Baker Street Irregulars.\n",
            "------------------------------------------------------------\n",
            "Q35: What London club is Mycroft Holmes most associated with?\n",
            "A: ”“I can give you no definite answer.”“You may say that the house is not a very congenial one, but that is the way it has been for some years. The other houses are very different. Mycroft was once in charge of one of them, but it was a small one and he was forced to sell it in order to give me a better starting-point.”“I see. Well, then, you must admit that it\n",
            "Expected:The Diogenes Club.\n",
            "------------------------------------------------------------\n",
            "Q36: What is the name of the ancient document recited by Reginald Musgrave?\n",
            "A: ”“The       Ecclesiastical Handbook, or Ecclesiastical Musgrave's       Handbook.”“May I have it?”“No, you will find it upon the table.”“Ah! you are not joking, are you? You are not       joking!”“What do you mean?”“I am going to ask you a very personal question\n",
            "Expected:The Musgrave Ritual.\n",
            "------------------------------------------------------------\n",
            "Q37: What injury does Victor Hatherley suffer during his adventure?\n",
            "A: ”“He has been struck by a fall.”“I see. He was a very active man.”“And you think he is dead?”“I think not.”“Well, if he is dead, what do you think of the woman?”“I do not know.”“But I should not wish her to be dead.”“I think she is an angel.”\n",
            "Expected:Loss of a thumb.\n",
            "------------------------------------------------------------\n",
            "Q38: On what moor do the Baskerville events occur?\n",
            "A: ”“In the Baskerville Shire.”“But why, then, did he not go to the Shire?”“Because he was very much in love with the girl, and was in some way attracted by her beauty.”“Ah, you are right,” said Holmes, smiling. “I must thank you, for it was a most painful experience for me.”“I have had no other experience of\n",
            "Expected:Dartmoor.\n",
            "------------------------------------------------------------\n",
            "Q39: What substance is used to make an animal appear ghostly?\n",
            "A: ”“Well,” said I, “it is a question which has been on my mind lately. I have no doubt that the old man has a very strong influence over the girl.”“Yes, I think that she is his daughter,” said he, “but I have no reason to believe that she is his wife.”“You are not convinced?”“Well, I don’t know.”\n",
            "Expected:Phosphorus.\n",
            "------------------------------------------------------------\n",
            "Q40: In which county is Dartmoor located?\n",
            "A: ”“In the north-west corner,” said he.“And where is the nearest railway station?”“The nearest station is in Woolwich, in the Surrey Downs.”“I see. But the station is not far.”“It is just a quarter of a mile away.”“Ah! that is interesting. Now, tell me about the house.”“It is a small, neat,\n",
            "Expected:Devonshire.\n",
            "------------------------------------------------------------\n",
            "Q41: What animal do Holmes and Watson sometimes use to track a scent?\n",
            "A: ”“I don’t know,” said I. “I thought that the dog would have been used for that.”“Ah! it is very likely,” he answered, “that the dog was on the track.”“And when did you first see it?”“I had just finished breakfast when I heard it.”“Was it just before you left the house?”“Yes\n",
            "Expected:A dog.\n",
            "------------------------------------------------------------\n",
            "Q42: What scientific field is Holmes notably skilled in?\n",
            "A: ”“He is, I believe, a naturalist, and that is his specialty. He has a curious, instinctive, and almost animal instinct. He has a keen perception of the habits and habits of his own kind, which, as I have remarked, are the most peculiar and unique in the animal world. His naturalist instincts are very strong, and he has, as you may imagine, a remarkable ability for the observation of the habits of others. He is a good observer\n",
            "Expected:Chemistry.\n",
            "------------------------------------------------------------\n",
            "Q43: Which police force does Holmes frequently assist?\n",
            "A: ”“The police force of Baker Street.”“What do you mean by that?”“You are a professional criminal investigator, Watson. You have the keenest interest in crime. I am aware that the case of the Baker Street murder is one which is of interest to every professional criminal investigator in England.”“Yes, indeed.”“And that you have been able to trace the murderer?”“I have no doubt\n",
            "Expected:Scotland Yard.\n",
            "------------------------------------------------------------\n",
            "Q44: What railway timetable does Holmes often consult?\n",
            "A: ”“It is a commonplace observation,” said he, “that the intervals between the journeys of a man’s life are not infrequent. It is not a very remarkable fact, but it is certainly an interesting one. Suppose for example that, in an early morning, I am driving from Waterloo to Reading, and am suddenly overtaken by a carriage which is a hundred yards behind me. I look round me, and the carriage is on the other side of me\n",
            "Expected:Bradshaw's.\n",
            "------------------------------------------------------------\n",
            "Q45: What supernatural creature is suspected in a case involving a South American family?\n",
            "A: ”“A mongoose.”“Then, I presume, it is a very formidable creature?”“Yes, sir.”“And it is not to be trifled with?”“Not at all.”“I see. Well, then, you will have the pleasure of seeing it. I have been told that you have a small collection of old books in your library. It is my duty to present them to\n",
            "Expected:A vampire.\n",
            "------------------------------------------------------------\n",
            "Q46: What quick message service does Holmes often use?\n",
            "A: ”“He never lets it go to waste. He has an idea of what he wants and always keeps it on his mind. But when I say that he has an idea of what he wants, it must be that he has an idea of what he is going to do.”“But he does not tell you what he wants?”“No; he only tells you what he thinks it will be worth. It is very rare that a man can tell you\n",
            "Expected:Telegrams.\n",
            "------------------------------------------------------------\n",
            "Q47: What handheld tool does Holmes use to inspect tiny clues?\n",
            "A: ”“His eyes are very sensitive. He will not look at a small object unless it is absolutely necessary. He is a very good observer.”“But how do you know that the key to this room is in the locked cabinet?”“I have been examining the cabinet myself.”“How is it that you know that the key is there?”“Because I have seen the key on the shelf.”“Then it\n",
            "Expected:A magnifying glass.\n",
            "------------------------------------------------------------\n",
            "Q48: In which city do most of Holmes's cases take place?\n",
            "A: ”“I have no doubt that London.”“Where is the nearest police-station?”“Not a very distant one,” I answered. “There is the great central police-station, and then there is the county police-station, and finally the Metropolitan Police Station.”“But you can see the train from here.”“Yes, we can see it.”“And you have heard the news\n",
            "Expected:London.\n",
            "------------------------------------------------------------\n",
            "Q49: After retirement, what hobby does Holmes pursue?\n",
            "A: ”“Oh, it is a curious matter. I have done a little of every sort of writing. I write a history of the Crimean War, and I have written a few little treatises upon various subjects. I have been a schoolmaster and a surgeon, and have now taken over a small practice in Kensington, which is a very popular one, and is a little above the market price.”“You have done the best that you can.”“\n",
            "Expected:Beekeeping.\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "questions = \"data/questions_sherlock.json\"\n",
        "out_file_name = \"pretrained_gpt2_answers.txt\"\n",
        "\n",
        "results = test_on_questions(prompt_builder=build_prompt, model_path=model_path, question_file=questions, out_file_name=out_file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Remarque\n",
        "Le pré-entraînement sur Sherlock Holmes améliore le vocabulaire et le style des réponses (mention de Baker Street, violin, London), mais les réponses restent trop longues et imprécises. Le modèle génère des dialogues fictifs plutôt que des réponses directes, ce qui montre la nécessité d'un affinage par instructions."
      ],
      "metadata": {
        "id": "f-LkGGxGmZj5"
      },
      "id": "f-LkGGxGmZj5"
    },
    {
      "cell_type": "markdown",
      "id": "2d73c5cc",
      "metadata": {
        "id": "2d73c5cc"
      },
      "source": [
        "## 5. Analyse des résultats"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d8e187a",
      "metadata": {
        "id": "5d8e187a"
      },
      "source": [
        "### 5.1 Évaluation quantitative (à compléter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a7a7226",
      "metadata": {
        "id": "7a7a7226"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def remove_articles(text):\n",
        "    return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "def white_space_fix(text):\n",
        "    return ' '.join(text.split())\n",
        "\n",
        "def remove_punc(text):\n",
        "    exclude = set(string.punctuation)\n",
        "    return ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "def lower(text):\n",
        "    return text.lower()\n",
        "\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Mettre en minuscule et retirer la ponctuation, des déterminants and les espaces.\"\"\"\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89d80fa7",
      "metadata": {
        "id": "89d80fa7"
      },
      "outputs": [],
      "source": [
        "def evaluate_f1(ground_truth, prediction):\n",
        "    \"\"\"Normalise les 2 textes, trouve ce qu'il y a en commun et estime précision, rappel et F1.\"\"\"\n",
        "    prediction_tokens = normalize_answer(prediction).split()\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0.0, 0.0, 0.0\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\n",
        "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return precision, recall, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eec8ec86",
      "metadata": {
        "id": "eec8ec86"
      },
      "outputs": [],
      "source": [
        "def evaluation_generation(results):\n",
        "    total_precision = 0\n",
        "    total_recall = 0\n",
        "    total_f1 = 0\n",
        "    num_questions = len(results)\n",
        "\n",
        "    # Calcule les métriques pour chaque question\n",
        "    for i, question, answer, expected_answer in results:\n",
        "        precision, recall, f1 = evaluate_f1(expected_answer, answer)\n",
        "        total_precision += precision\n",
        "        total_recall += recall\n",
        "        total_f1 += f1\n",
        "\n",
        "    # Calcule les moyennes\n",
        "    eval = {\n",
        "        'precision_moyenne': total_precision / num_questions,\n",
        "        'rappel_moyen': total_recall / num_questions,\n",
        "        'f1_moyen': total_f1 / num_questions,\n",
        "        'nombre_questions': num_questions\n",
        "    }\n",
        "    return eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0044a2a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0044a2a4",
        "outputId": "0ba97075-d321-491b-b924-ce17570e5417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'precision_moyenne': 0.003935810574107621, 'rappel_moyen': 0.0861904761904762, 'f1_moyen': 0.007400289606916743, 'nombre_questions': 50}\n"
          ]
        }
      ],
      "source": [
        "eval = evaluation_generation(results)\n",
        "print(eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53cfb4d1",
      "metadata": {
        "id": "53cfb4d1"
      },
      "source": [
        "**Question :** Que pensez-vous de cette évaluation ?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ecc9e77",
      "metadata": {
        "id": "5ecc9e77"
      },
      "source": [
        "Les résultats sont très faibles (F1 = 0.74%, précision = 0.39%, rappel = 8.6%), mais cela ne signifie pas que le modèle n'a rien appris. Ces scores bas s'expliquent par l'inadéquation de la métrique F1 avec ce type de tâche : le modèle génère des réponses très longues et narratives alors que les réponses attendues sont courtes.\n",
        "\n",
        "Par exemple, pour \"What instrument does Holmes play?\", le modèle répond \"I play a violin. But he can play a harp...\" au lieu de simplement \"The violin\". L'information est présente mais noyée dans du texte superflu.\n",
        "\n",
        "Cette évaluation montre surtout que le pré-entraînement seul ne suffit pas : le modèle a appris le style et le vocabulaire de Sherlock Holmes, mais il a besoin d'un affinage par instructions pour apprendre à répondre de manière concise et directe."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbb1b717",
      "metadata": {
        "id": "fbb1b717"
      },
      "source": [
        "## 5. Analyse qualitative (à faire)\n",
        "\n",
        "Rédigez **5 à 15 phrases** présentant vos observations et expliquant pourquoi, selon vous, le modèle fournit ce type de réponses.\n",
        "\n",
        "Vous pouvez ajouter des cellules au besoin.\n",
        "\n",
        "> Cette étape prépare le terrain pour la tâche 4."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Le modèle GPT-2 pré-entraîné sur les textes de Sherlock Holmes montre des améliorations notables par rapport au modèle de base (tâche 2), mais présente encore des limites importantes. On observe que le modèle a assimilé le vocabulaire spécifique de l'univers Sherlock Holmes : il mentionne maintenant correctement des éléments comme \"Baker Street\", \"violin\", \"revolver\" et \"London\", ce qui était absent dans les réponses du modèle de base.\n",
        "\n",
        "Cependant, le modèle génère systématiquement des réponses beaucoup trop longues et verbeuses au lieu de fournir des réponses factuelles courtes et directes. Cette verbosité s'explique par le fait que le modèle a été entraîné sur des romans narratifs où les informations sont présentées sous forme de dialogues et de descriptions élaborées, et non sous forme de questions-réponses concises. Le modèle a donc appris à \"raconter des histoires\" plutôt qu'à répondre directement aux questions.\n",
        "\n",
        "On remarque également que le modèle éprouve des difficultés à fournir des noms propres précis (comme \"Mycroft Holmes\", \"Irene Adler\" ou \"Professor Moriarty\") et préfère générer des descriptions génériques ou inventer des noms alternatifs. Cela suggère que le simple pré-entraînement sur les textes ne suffit pas pour extraire et mémoriser des faits précis de manière structurée.\n",
        "\n",
        "En conclusion, le pré-entraînement a permis d'acquérir le style, le vocabulaire et certaines connaissances générales sur l'univers de Sherlock Holmes, mais le modèle manque encore de la capacité à produire des réponses courtes, précises et factuelles. Ces observations indiquent clairement la nécessité d'une étape d'affinage par instructions (tâche 4) qui apprendra au modèle à répondre de manière structurée en format question-réponse, plutôt que de générer des récits narratifs."
      ],
      "metadata": {
        "id": "ORpulBAEodR8"
      },
      "id": "ORpulBAEodR8"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9J2opuZMocc1"
      },
      "id": "9J2opuZMocc1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "38c1affa",
      "metadata": {
        "id": "38c1affa"
      },
      "source": [
        "   "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a2ab8cc6f4d34c92b0be69ab2c472bc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2058c2dc452644d09eac9543c1cd2744",
              "IPY_MODEL_c73a79ff61564dc290056ba84384b733",
              "IPY_MODEL_9fa1c2bc8694422e87a307a3fb6dc874"
            ],
            "layout": "IPY_MODEL_75eb4886cd41410295f431fe81e718fc"
          }
        },
        "2058c2dc452644d09eac9543c1cd2744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91d0252492c748c1bbe9b53c87e0d647",
            "placeholder": "​",
            "style": "IPY_MODEL_7c78590ef1444f1990a81eeb1ba8b698",
            "value": "Map: 100%"
          }
        },
        "c73a79ff61564dc290056ba84384b733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3af8a83391534831bdb2711a5d8c1001",
            "max": 11052,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d817a17974b43b98d0f20e94eeffb91",
            "value": 11052
          }
        },
        "9fa1c2bc8694422e87a307a3fb6dc874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e07de7308ad4d1eab1572dd1b59bfa5",
            "placeholder": "​",
            "style": "IPY_MODEL_08f9d6970c7d466d9aff1a0095e76d16",
            "value": " 11052/11052 [00:02&lt;00:00, 5703.05 examples/s]"
          }
        },
        "75eb4886cd41410295f431fe81e718fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91d0252492c748c1bbe9b53c87e0d647": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c78590ef1444f1990a81eeb1ba8b698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3af8a83391534831bdb2711a5d8c1001": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d817a17974b43b98d0f20e94eeffb91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e07de7308ad4d1eab1572dd1b59bfa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08f9d6970c7d466d9aff1a0095e76d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77ede7036bb64f998de06aa93e2ffc5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9175319774a14bdc8a7618addfcf3135",
              "IPY_MODEL_ce352f88d39044fb8d398de87dc3aba8",
              "IPY_MODEL_b887f9ee04934970a8565f696bbd1af1"
            ],
            "layout": "IPY_MODEL_880851fe0dc54d04b541548a402bda36"
          }
        },
        "9175319774a14bdc8a7618addfcf3135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34dce65d31a84dc3b051f80f9ef6b6af",
            "placeholder": "​",
            "style": "IPY_MODEL_c4d6263e3306473ea5c5935ac9f91457",
            "value": "Map: 100%"
          }
        },
        "ce352f88d39044fb8d398de87dc3aba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df7e767ee4f84f30be23f2af183a3523",
            "max": 11052,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb9ae1e3a09e4d7d9e7b2cdbbde60b61",
            "value": 11052
          }
        },
        "b887f9ee04934970a8565f696bbd1af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7be790e8a28f422482561b9f3c852226",
            "placeholder": "​",
            "style": "IPY_MODEL_e81e30ec2ca14f518fe040314b5c9aac",
            "value": " 11052/11052 [00:02&lt;00:00, 4613.29 examples/s]"
          }
        },
        "880851fe0dc54d04b541548a402bda36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34dce65d31a84dc3b051f80f9ef6b6af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4d6263e3306473ea5c5935ac9f91457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df7e767ee4f84f30be23f2af183a3523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb9ae1e3a09e4d7d9e7b2cdbbde60b61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7be790e8a28f422482561b9f3c852226": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e81e30ec2ca14f518fe040314b5c9aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}