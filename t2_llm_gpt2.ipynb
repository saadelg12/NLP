{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4d53d4c2",
      "metadata": {
        "id": "4d53d4c2"
      },
      "source": [
        "# Tâche 2 : Question-réponse avec modèle pré‑entraîné GPT‑2, sans adaptation\n",
        "\n",
        "**Objectifs**\n",
        "\n",
        "Observer les limites d’un modèle de langage **pré‑entraîné** (**GPT-2 Medium (355M)**) lorsqu’on lui pose des questions sur un sujet **absent** de ses données d’origine (ici, l’univers de *Sherlock Holmes*).\n",
        "Dans ce *notebook*, vous faites **uniquement de l’inférence** avec un modèle qui a déjà été pré-entraîné. Cette tâche consiste à construire un *prompt* minimal, générer des réponses avec le modèle sans modification, puis évaluer la pertinence des résultats. Aucun entraînement de modèle n'est effectué pour cette tâche.\n",
        "\n",
        "**Objectifs d’apprentissage**\n",
        "1. Charger un modèle pré‑entraîné et son tokenizer de Hugging Face.\n",
        "2. Générer du texte et **isoler la réponse** du modèle.\n",
        "3. Comprendre et expliquer les **limites du pré‑entraînement** hors‑domaine.\n",
        "\n",
        "Les **questions** pour évaluer le modèle vous sont fournies. Vous devez comprendre le format des questions chargées en mémoire.\n",
        "\n",
        "> Il est recommandé de faire ce travail pratique en utilisant une carte graphique GPU compatible avec HuggingFace/Pytorch.\n",
        "> Si votre machine n’en possède pas, vous pouvez utiliser **Google Colab** pour exécuter le *notebook* dans le cloud."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81af0ea3655c4578",
      "metadata": {
        "id": "81af0ea3655c4578"
      },
      "source": [
        "Si nécessaire, installer les *packages* suivant. Si vous exécutez sur Code Colab, ces *packages* devraient déjà être installés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P1jvDsOV7WVW",
      "metadata": {
        "id": "P1jvDsOV7WVW"
      },
      "outputs": [],
      "source": [
        "#!pip install datasets\n",
        "#!pip install accelerate\n",
        "#!pip install transformers[torch]\n",
        "#!pip3 install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4d460d1d84efc873",
      "metadata": {
        "id": "4d460d1d84efc873"
      },
      "outputs": [],
      "source": [
        "batch_size = 5 # il est possible d'ajuster la taille de batch. Les valeurs actuelles utilisent environ 10 Gb\n",
        "max_length = 256 # on réduit le contexte pour sauver du temps, nos exemples ne nécesside pas une plus grande fenêtre de mots\n",
        "model_name = \"gpt2-medium\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "660a299e09c87174",
      "metadata": {
        "id": "660a299e09c87174"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffc5be8b4054923c",
      "metadata": {
        "id": "ffc5be8b4054923c"
      },
      "source": [
        "## 1. Chargement du modèle Hugging Face et du tokenizer (à compléter)\n",
        "\n",
        "Complétez le corps de la fonction `load_model(model_path)` afin qu’elle :\n",
        "\n",
        "- charge le **tokenizer** et le **modèle** Hugging Face à partir du chemin `model_path`.\n",
        "- **retourne** le tokenizer comme **première valeur de retour** et le modèle comme **seconde valeur de retour**.\n",
        "\n",
        "On ajoute également des fonctions pour monter les questions en mémoire et pour sauvegarder les réponses dans un fichier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "839fc2cb34773ade",
      "metadata": {
        "id": "839fc2cb34773ade"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "def load_model(model_path):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "\n",
        "    # GPT-2 n'en a pas par défaut\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        model.config.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "    return tokenizer, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4c56a1e65ebeb313",
      "metadata": {
        "id": "4c56a1e65ebeb313"
      },
      "outputs": [],
      "source": [
        "def load_entries(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "    if not isinstance(data, list):\n",
        "        raise ValueError(f\"Question file must contain a list of objects. Got: {type(data)}\")\n",
        "    return data\n",
        "\n",
        "def save_answers(questions_answers, output_dir, out_file_name, display=True):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    with open(os.path.join(output_dir, out_file_name), \"w\", encoding=\"utf-8\") as out:\n",
        "        for index, question, answer, expected_answer in questions_answers:\n",
        "            out.write(f\"Q: {question}\\nA: {answer}\\nExpected:{expected_answer}\\n{'-' * 60}\\n\")\n",
        "            if display:\n",
        "                print(f\"Q{index}: {question}\\nA: {answer}\\nExpected:{expected_answer}\\n{'-' * 60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2300e4992db278ff",
      "metadata": {
        "id": "2300e4992db278ff"
      },
      "source": [
        "## 2. Fonctions de test question-réponse  (à compléter)\n",
        "\n",
        "La fonction **test_on_questions** est utilisée pour parcourir **toutes les entrées** du fichier de questions afin de produire des réponses générées par le modèle.\n",
        "\n",
        "La génération d'une réponse à une question implique les étapes suivantes (fonction **process_entry** à compléter) :\n",
        "* Construire un prompt à l’aide de la fonction **build_prompt** (rendu disponible).\n",
        "* Utiliser le modèle (via un pipeline de génération passé en argument) pour générer une réponse à une question.\n",
        "* Retourner la réponse générée par le modèle.  \n",
        "\n",
        "Points importants à souligner:\n",
        "* La fonction ***process_entry*** doit retourner uniquement la réponse générée par le modèle (sans la question - le prompt).\n",
        "* Il est de votre responsabililté de choisir **les paramètres** du générateur (max_new_tokens, do_sample, temperature, top_k ou top_p). Décrivez ceux que vous avez retenus.\n",
        "\n",
        "> Afin de simplifier le travail, nous avons choisi de ne pas utiliser de *batchs* dans la fonction qui teste les questions.\n",
        "> Vous n'avez pas à prendre en compte le *warning* qui suggère d'utiliser des *datasets*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b01c1a71",
      "metadata": {
        "id": "b01c1a71"
      },
      "outputs": [],
      "source": [
        "def build_prompt(entry):\n",
        "    return entry.get(\"question\", \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef5e3424",
      "metadata": {
        "id": "ef5e3424"
      },
      "source": [
        "### Description des paramètres de génération:\n",
        "- **max_new_tokens=100** : Limite la longueur de la réponse à 100 tokens pour éviter des réponses trop longues\n",
        "- **do_sample=True** : Active l'échantillonnage probabiliste pour des réponses plus variées et naturelles\n",
        "- **temperature=0.7** : Contrôle la créativité (0.7 offre un bon équilibre entre cohérence et diversité)\n",
        "- **top_p=0.9** : Considère les tokens dont la probabilité cumulative atteint 90%\n",
        "- **top_k=50**: Limite la sélection aux 50 tokens les plus probables à chaque étape\n",
        "- **pad_token_id** : Nécessaire pour éviter les warnings avec GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ddcab8bb4bf71997",
      "metadata": {
        "id": "ddcab8bb4bf71997"
      },
      "outputs": [],
      "source": [
        "def process_entry(entry, prompt_builder, generator):\n",
        "    # Construit le prompt à partir de l'entrée\n",
        "    prompt = prompt_builder(entry)\n",
        "\n",
        "    # Génére la réponse avec le modèle\n",
        "    result = generator(\n",
        "        prompt,\n",
        "        max_new_tokens=100,       # Longueur maximale de la réponse\n",
        "        do_sample=True,           # Active l'échantillonnage probabiliste\n",
        "        temperature=0.7,          # Contrôle la créativité\n",
        "        top_p=0.9,                # Échantillonnage nucleus\n",
        "        top_k=100,                # Échantillonnage top-k\n",
        "        pad_token_id=generator.tokenizer.eos_token_id  # Évite les warnings\n",
        "    )\n",
        "\n",
        "    # Extrait le texte généré complet\n",
        "    generated_text = result[0]['generated_text']\n",
        "\n",
        "    # Retourne uniquement la réponse (enleve le prompt)\n",
        "    answer = generated_text[len(prompt):].strip()\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "SNoZIz5b_DFo",
        "outputId": "ef438423-4044-41ec-f467-d7e67e0e96f1"
      },
      "id": "SNoZIz5b_DFo",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a7a85afb324813ff",
      "metadata": {
        "id": "a7a85afb324813ff"
      },
      "outputs": [],
      "source": [
        "def test_on_questions(prompt_builder, model_path, question_file, out_file_name, output_dir=\"results\"):\n",
        "    entries = load_entries(question_file)\n",
        "    tokenizer, model = load_model(model_path)\n",
        "    generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "    results = []\n",
        "    for i, entry in enumerate(entries):\n",
        "        answer = process_entry(entry, prompt_builder, generator)\n",
        "        question = entry.get(\"question\", \"\")\n",
        "        expected_answer = entry.get(\"answer\", \"\")\n",
        "        results.append((i, question, answer, expected_answer))\n",
        "    save_answers(results, output_dir, out_file_name, display=True)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19259c4ffd3291b2",
      "metadata": {
        "id": "19259c4ffd3291b2"
      },
      "source": [
        "## 3. Génération avec GPT-2 de réponses aux questions sur Sherlock Holmes\n",
        "\n",
        "Exécutez la cellule suivante pour générer les réponses aux questions.\n",
        "Le temps d’exécution devrait se situer entre **5 et 10 minutes** si vous utilisez **Google Colab** avec un GPU.\n",
        "\n",
        "Note : N'oubliez pas d'ajouter le fichier de réponses générées par le modèle (voir *out_file_name*) dans votre remise du travail. Ainsi le fichier ZIP que vous déposerez sur le site du cours devra contenir tous les *notebooks* et tous les fichiers de réponses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4f6e7995f5a08f31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f6e7995f5a08f31",
        "outputId": "931f0f19-cafd-42cc-c331-87d9543c0650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q0: Where do Sherlock Holmes and Dr. Watson live?\n",
            "A: It's a good question. Sherlock Holmes lived in a hotel in London, which is not exactly the place to start a novel. He lived in the hotel, of course. But then, the hotel was not the place to start a novel, so Holmes lived in a boarding house, in which he was kept in a perpetual state of stasis, and which he had to rely on his faithful companion, Watson. (Watson is a bit of a mystery, since he seems to be\n",
            "Expected:221B Baker Street, London.\n",
            "------------------------------------------------------------\n",
            "Q1: Who is Sherlock Holmes' loyal friend and chronicler?\n",
            "A: Who is his rival? Who is his nemesis? What is his ultimate goal?\n",
            "\n",
            "Sherlock Holmes is a serial killer, a mad scientist, a spy, a psychiatrist, a detective, a spy, a killer, a philosopher, a detective, a spy, a killer, a spy, a spy, a spy, a spy, a spy, a spy, a spy, a spy, a spy, a spy, a spy, a spy, a spy, a spy,\n",
            "Expected:Dr. John H. Watson.\n",
            "------------------------------------------------------------\n",
            "Q2: Who is considered 'The Woman' by Sherlock Holmes?\n",
            "A: The first woman to appear in Sherlock Holmes was Mary Martin, who was a well-known writer and poet who wrote under the pen name Mary Martin. She was married to John Watson, and she had three children: Mary, Mary and Mary Martin.\n",
            "\n",
            "She was born in 1526 and died in 1633.\n",
            "\n",
            "She was an accomplished poet, and she wrote many of the poems and stories of Sherlock Holmes. She wrote for a number of literary magazines, including The Magazine of\n",
            "Expected:Irene Adler.\n",
            "------------------------------------------------------------\n",
            "Q3: Which story features the Red-Headed League?\n",
            "A: http://www.bibdsl.co.uk/w10-images/l/MM00251218.jpg\n",
            "\n",
            "The Drowned City DVD / Normal Retail / Rental 12/10/2018 20th Century Fox Home Entertainment All the action and adventure as the children of the future struggle to survive in the bleak world of the Drowned City.\n",
            "\n",
            "http://www.bibdsl.co.uk/w10-images/l\n",
            "Expected:The Adventure of the Red-Headed League.\n",
            "------------------------------------------------------------\n",
            "Q4: What is the primary occupation of Sherlock Holmes?\n",
            "A: Sherlock Holmes is the author of the books Sherlock Holmes: A Study in Scarlet, The Adventure of the Empty House, and The Adventure of the Empty House: A Study in Scarlet. He has written several of the books Sherlock Holmes: A Study in Scarlet, The Adventure of the Empty House, and The Adventure of the Empty House: A Study in Scarlet. He is also the co-author of The Adventure of the Empty House: A Study in Scarlet, A Study in Scarlet: A\n",
            "Expected:Consulting detective.\n",
            "------------------------------------------------------------\n",
            "Q5: Who is Sherlock Holmes' arch-nemesis?\n",
            "A: The man who invented Sherlock Holmes\n",
            "\n",
            "The man who invented Sherlock Holmes is known as \"Sherlock the Man\". The character is most often depicted as a man in his late 40s or early 50s, with a thinning beard and a stoic, stoic expression. He is a charismatic, charismatic, charismatic person who speaks with a deep, confident voice. He is a professional detective who has become a household name due to his success in solving the murders of the British Empire's\n",
            "Expected:Professor James Moriarty.\n",
            "------------------------------------------------------------\n",
            "Q6: What musical instrument does Sherlock Holmes play?\n",
            "A: Sherlock Holmes is an iconic figure in popular culture. He is the most popular character in the Sherlock Holmes stories, the first Sherlock Holmes story to be adapted for television, and the first Sherlock Holmes movie to be released. He is the oldest character in the Sherlock Holmes stories, and the oldest man in the series.\n",
            "\n",
            "In addition to his distinctive voice, Sherlock Holmes is a well-known and well-respected actor. He has won numerous Academy Awards for his performances, including Best Actor\n",
            "Expected:The violin.\n",
            "------------------------------------------------------------\n",
            "Q7: What is the name of Sherlock Holmes' elder brother?\n",
            "A: A: Sir Arthur Conan Doyle, Sherlock Holmes\n",
            "\n",
            "Q: I'm going to be in my 60s this year. I'm going to be in my 60s. How do I know I'm not old?\n",
            "\n",
            "A: It's not a matter of age, but of a certain age, which is really hard to predict. There's no doubt that when I'm in my 60s I have a different quality of life than I had when I was in my 20s\n",
            "Expected:Mycroft Holmes.\n",
            "------------------------------------------------------------\n",
            "Q8: What is the blue gemstone found inside a Christmas goose called?\n",
            "A: It's called a Blue Gemstone. It is a type of gemstone that is found inside the body of a Christmas goose. It's an amazing gemstone, and I'm so glad to be able to share it with you. The Blue Gemstone is a special, unique gemstone that is found inside the body of a Christmas goose. It's really beautiful. It's called a blue gemstone, because blue is the color of the gemstone.\n",
            "\n",
            "And what is the\n",
            "Expected:The Blue Carbuncle.\n",
            "------------------------------------------------------------\n",
            "Q9: What residue does Holmes often analyze to identify smokers?\n",
            "A: \"We have a lot of data about the way the brain works. And we can see that smoking is associated with changes in brain structure,\" Holmes said. \"If we know that people who are smokers are more likely to have abnormalities in the brain that are associated with smoking, that's an important discovery.\"\n",
            "\n",
            "The findings were published this week in the journal Science.\n",
            "\n",
            "For Holmes, smoking has been a long-standing concern. His mother and father were both smokers.\n",
            "Expected:Tobacco ash.\n",
            "------------------------------------------------------------\n",
            "Q10: What tactic besides observation does Holmes often use to gather information?\n",
            "A: He keeps a log of what he sees. He records all of the things he sees and does. He has a camera so he can look at what's going on around him and see what's going on in the other rooms. He doesn't have a camera on his bed. He has a recorder in his apartment that records everything.\n",
            "\n",
            "What's the most surprising thing he's seen?\n",
            "\n",
            "One day he was sitting on the floor and he noticed that there was a baby sitting\n",
            "Expected:Disguise.\n",
            "------------------------------------------------------------\n",
            "Q11: What was the profession of Dr. John Watson?\n",
            "A: The profession of Dr. John Watson was a research scientist in the field of evolutionary theory. He was an American born in 1845 in the town of Westlake, Illinois. He received his doctorate in 1874 from the University of Illinois at Urbana-Champaign, and became an associate professor of biology in 1885 at the University of Chicago.\n",
            "\n",
            "He served as a professor of chemistry at the University of Chicago from 1892 to 1896, and as professor of chemistry at\n",
            "Expected:Doctor.\n",
            "------------------------------------------------------------\n",
            "Q12: What kind of marks on the ground does Holmes often study to track people?\n",
            "A: \"It depends on what we're looking for,\" says Holmes. \"There are a lot of things we look for. We look for a pattern of movement, a pattern of activity, whether it's a car, whether it's a building, whether it's a body. We can find patterns that are more subtle. That's the beauty of it.\"\n",
            "\n",
            "Holmes says that his research is especially useful for the police and other officials because it allows them to observe the behavior of individuals\n",
            "Expected:Footprints.\n",
            "------------------------------------------------------------\n",
            "Q13: Who is the landlady of 221B Baker Street?\n",
            "A: The landlady is a woman in her early thirties, with a long, dark, wavy, black hair. She wears a dark grey shirt and a dark blue skirt, and her shoes are black with white laces. She wears a pair of black, long, black trousers, with white laces. She wears a pair of black, long, black shoes. She has a short, dark, wavy, black hair.\n",
            "\n",
            "Who is the man who is\n",
            "Expected:Mrs. Hudson.\n",
            "------------------------------------------------------------\n",
            "Q14: What substance did Sherlock Holmes sometimes use to stimulate his mind?\n",
            "A: Was it an opium substitute or an aloe vera?\n",
            "\n",
            "The answer is, of course, both.\n",
            "\n",
            "In Sherlock Holmes and the Mystery of the Empty House, the author of The Adventure of the Empty House, wrote:\n",
            "\n",
            "The author of the famous \"Empty House\" story was a man called Sherlock Holmes. When he was younger he was a boy of about twelve, but he became a man of great genius. He was one of the most extraordinary and important men of his\n",
            "Expected:Cocaine.\n",
            "------------------------------------------------------------\n",
            "Q15: Who is the Scotland Yard detective that often consults Holmes?\n",
            "A: He is Detective Chief Inspector Tim Scott.\n",
            "\n",
            "He is also the former head of Scotland Yard's Crime and Policing Command.\n",
            "\n",
            "And he has worked in the UK since 2004.\n",
            "\n",
            "What is his career record?\n",
            "\n",
            "He has worked in the UK since 2004, when he was head of Scotland Yard's Crime and Policing Command.\n",
            "\n",
            "What's his background?\n",
            "\n",
            "He was born in Glasgow in the 1960s. He was the son of a policeman who\n",
            "Expected:Inspector Lestrade (Gregson or Bradstreet also acceptable).\n",
            "------------------------------------------------------------\n",
            "Q16: What warning arrives as envelopes containing dried orange seeds?\n",
            "A: No. The seeds were dried at the factory and no one was aware of any risks to the public, the Ministry of Environment said.\n",
            "\n",
            "Why are the seeds so hard to come by?\n",
            "\n",
            "The seeds were originally intended to be used for the production of sugarcane, but the factory was closed by the end of 2009, when it was discovered that the factory was producing bananas.\n",
            "\n",
            "In 2010, the factory's workers were told to cut down the trees and plant the\n",
            "Expected:Five orange pips.\n",
            "------------------------------------------------------------\n",
            "Q17: What is the bog near Baskerville Hall called?\n",
            "A: Bog is the English word for \"baggage\" in English. It's one of the most common words in the English language and means \"to pack\". It is sometimes used as a nickname. The term refers to the people who work in the building of houses, especially in the early days of the English settlement.\n",
            "\n",
            "What is the name of the town called?\n",
            "\n",
            "The name of the town is called Baskerville. The town was founded in 1685 and is\n",
            "Expected:The Grimpen Mire.\n",
            "------------------------------------------------------------\n",
            "Q18: Which London newspaper does Holmes frequently read?\n",
            "A: \"The New York Times,\" he says. \"I'm an avid reader of the Times, so I've read the New York Times, the Washington Post, the Los Angeles Times, the New York Times Magazine, the Wall Street Journal. I read the London Times a lot. I've read a lot of magazines, and I read a lot of newspapers. I've read a lot of books, and I've read a lot of books about sports. I read a lot of books about\n",
            "Expected:The Times.\n",
            "------------------------------------------------------------\n",
            "Q19: What kind of drawings form the code that Holmes deciphers on walls and paper?\n",
            "A: A kind of art. A kind of poetry. A kind of music. A kind of art. A kind of poetry. A kind of music. A kind of music. A kind of art. A kind of poetry. A kind of music. A kind of music. A kind of music. A kind of poetry. A kind of music. A kind of music. A kind of music. A kind of music. A kind of poetry. A kind of music. A kind of\n",
            "Expected:Dancing stick figures.\n",
            "------------------------------------------------------------\n",
            "Q20: What kind of jewel is set in the damaged coronet handled by a banker?\n",
            "A: This jewel is not set in the damaged coronet of a banker.\n",
            "\n",
            "This jewel is set in the damaged coronet of a banker.\n",
            "\n",
            "This jewel is set in the damaged coronet of a banker.\n",
            "\n",
            "This jewel is set in the damaged coronet of a banker.\n",
            "\n",
            "This jewel is set in the damaged coronet of a banker.\n",
            "\n",
            "This jewel is set in the damaged coronet of a banker.\n",
            "\n",
            "This jewel is set in the damaged\n",
            "Expected:Beryls.\n",
            "------------------------------------------------------------\n",
            "Q21: What combat sport is Holmes proficient in?\n",
            "A: \"I'm pretty good at all the sports that I've been in.\"\n",
            "\n",
            "Is he a good fighter?\n",
            "\n",
            "\"I'm not sure I can say that I'm really good at fighting. But I know how to hit people in the face. I know how to hit people in the head. I've fought guys in the ring who have got more experience than I do. I think I'm a very good fighter, but I don't think I'm a very good fighter\n",
            "Expected:Boxing.\n",
            "------------------------------------------------------------\n",
            "Q22: What does Sherlock Holmes keep in his Persian slipper?\n",
            "A: His own personal collection of books and a copy of The Canterbury Tales.\n",
            "\n",
            "A note to his friend and former lover, the late, great, and most beloved of all writers, Sir Arthur Conan Doyle.\n",
            "\n",
            "And, if you're wondering what the most dangerous man in the world would wear, here's a little hint: it's not the Slipper.\n",
            "\n",
            "Now that you know what it is, what are your thoughts on the Slipper? Are you impressed by the\n",
            "Expected:Pipe tobacco.\n",
            "------------------------------------------------------------\n",
            "Q23: In which room at 221B do most client interviews happen?\n",
            "A: At 221B there is a bar and a small restaurant, but most of the time, clients are taken to a room with a full kitchen and bar. This is the room where the interview takes place.\n",
            "\n",
            "What type of room does the interview take place in?\n",
            "\n",
            "The room where the client's interview takes place is an open room with a couch and chairs.\n",
            "\n",
            "Can I have the client's picture taken with me?\n",
            "\n",
            "You are welcome to take the client's\n",
            "Expected:The sitting-room.\n",
            "------------------------------------------------------------\n",
            "Q24: What important document goes missing from the Foreign Office in one case?\n",
            "A: The Foreign Office has been using this to blackmail me. I am now suing them, to get a copy of the documents.\n",
            "\n",
            "The Daily Telegraph reported that the files were found in the possession of a man called \"Oleg\" and his wife, who were both Russian citizens.\n",
            "\n",
            "The documents have been turned over to the Foreign Office by their Russian owners, who are now in the process of returning them to their country of origin.\n",
            "\n",
            "The Russian government has been contacted for\n",
            "Expected:A secret naval treaty.\n",
            "------------------------------------------------------------\n",
            "Q25: What hot drink is often served at Baker Street?\n",
            "A: The hot drink, or \"hot-dog\" is served in the city's most famous bar, Baker Street, which is located in the heart of the Old City district. The street itself has been known to attract hundreds of thousands of visitors to enjoy a hot drink of any kind.\n",
            "\n",
            "Baker Street is also known for its eclectic mix of restaurants, bars, and nightclubs. A number of restaurants in the Old City district, such as the \"Luxury\" Hotel,\n",
            "Expected:Tea.\n",
            "------------------------------------------------------------\n",
            "Q26: What object ties Irene Adler to a scandal with a European king?\n",
            "A: The mystery surrounding Irene Adler's death has been solved, and the culprit is a woman who claims to have been the \"Queen of the Night\".\n",
            "\n",
            "In the past, Irene Adler was a spy for a mysterious figure named \"The Queen of the Night\". She was tasked with infiltrating a secret society called the Night, which was run by a mysterious man called \"The King of the Night\". She was assigned to spy on the group while they were in a meeting\n",
            "Expected:A compromising photograph.\n",
            "------------------------------------------------------------\n",
            "Q27: What weapon does Dr. Watson often carry?\n",
            "A: In Dr. Watson's case, he carries a two-handed sword. But he also carries a long sword, a mace, a whip, a dagger, and a baseball bat.\n",
            "\n",
            "The last item in the list is a baseball bat. What do you think about that?\n",
            "\n",
            "If you're a fan of baseball, you should be excited about Dr. Watson's role in the upcoming \"Game of Thrones\" movie. \"Game of Thrones\" stars Kit Harington\n",
            "Expected:A revolver.\n",
            "------------------------------------------------------------\n",
            "Q28: In which country did Dr. Watson serve as an army doctor?\n",
            "A: Dr. Watson served as a doctor at the British Army Medical School in London. He was in the Army from 1841 to 1842, when he was commissioned as a surgeon. He was stationed at St. Paul's Hospital in London, and in 1846, was appointed a surgeon, and on March 10, 1847, he was promoted to Major.\n",
            "\n",
            "In 1848, Dr. Watson became an officer of the Royal Navy, and was stationed at the London Navy Yard.\n",
            "Expected:Afghanistan.\n",
            "------------------------------------------------------------\n",
            "Q29: What is the missing racehorse’s name in the Dartmoor case?\n",
            "A: ‒\n",
            "\n",
            "Clyde: I'm sure you could guess.\n",
            "\n",
            "What about the missing horse's name?‒\n",
            "\n",
            "Clyde: I'm sure you could guess.\n",
            "\n",
            "So what about the missing horse's name?‒\n",
            "\n",
            "Clyde: I'm sure you could guess.\n",
            "\n",
            "What about the missing horse's name?‒\n",
            "\n",
            "Clyde: I'm sure you could guess.\n",
            "\n",
            "So what about the missing horse's\n",
            "Expected:Silver Blaze.\n",
            "------------------------------------------------------------\n",
            "Q30: What London vehicle do Holmes and Watson frequently hire for short trips?\n",
            "A: On the same day that he was arrested, Holmes and Watson were seen leaving a London flat. The pair were seen leaving a hotel in the early hours of the morning. The pair were spotted leaving the London flat at around 1am.\n",
            "\n",
            "It is understood that Holmes and Watson are staying at the same hotel.\n",
            "\n",
            "The pair were spotted leaving the London flat at around 1am. The pair were spotted leaving the London flat at around 1am. The pair were spotted leaving the London\n",
            "Expected:A hansom cab.\n",
            "------------------------------------------------------------\n",
            "Q31: In which English county do Holmes and Watson investigate a deadly household powder?\n",
            "A: The first Holmes and Watson episode is called The Resurrected. It begins with a conversation between Holmes and Watson.\n",
            "\n",
            "The story follows a man who gets very ill. He is taken to a doctor, and is sent to a hospital in London. It is at this hospital that Holmes and Watson investigate the case of the dead man.\n",
            "\n",
            "The story begins with Holmes and Watson getting drunk. Watson is having a bad time of it.\n",
            "\n",
            "It's a time for Watson\n",
            "Expected:Cornwall.\n",
            "------------------------------------------------------------\n",
            "Q32: Where does Holmes retire?\n",
            "A: Holmes will be back in the ring at the end of June.\n",
            "\n",
            "What will happen to the ring?\n",
            "\n",
            "The ring will be converted into a \"Holmes Hall of Fame,\" where Holmes will be honored and celebrated. The hall will be a major fundraiser for the family.\n",
            "\n",
            "What does it mean for the fans?\n",
            "\n",
            "Holmes will be the first person inducted into the Hall of Fame, and the first person to be inducted in a professional wrestling ring\n",
            "Expected:Sussex Downs.\n",
            "------------------------------------------------------------\n",
            "Q33: What does Watson call Holmes’ method of reasoning?\n",
            "A: It is a method of reasoning that is quite like the deductive reasoning employed by philosophers. It is based on the premise that all propositions are true unless they are contradicted by some evidence, and that any evidence that contradicts any proposition is false.\n",
            "\n",
            "According to Watson, Holmes has come up with a way to prove that all propositions are true unless they contradict each other, but he has not found any evidence to support this. Watson's method is based on a set of statements that is called a hypothesis\n",
            "Expected:“The science of deduction and analysis.”\n",
            "------------------------------------------------------------\n",
            "Q34: What is the name of the street‑boy network Holmes employs?\n",
            "A: HOLMES: The street‑boy network is a sort of network of street‑boys. We have a number of street‑boys that we have trained and that are also working with us, and that are also going through the school and other schools. We have some street‑boys that are involved in the school and other schools.\n",
            "\n",
            "We have a number of street‑boys that we have trained and that are also going through the school and other schools. We have some street\n",
            "Expected:The Baker Street Irregulars.\n",
            "------------------------------------------------------------\n",
            "Q35: What London club is Mycroft Holmes most associated with?\n",
            "A: If you're asking me, it would have to be Manchester United. They're the best team in the world. The way they play is incredible.\n",
            "\n",
            "What's the most famous Holmes story?\n",
            "\n",
            "That I was the first person to invent the phrase \"lunchtime\" in the form of a joke.\n",
            "\n",
            "What's the most famous Holmes story of all time?\n",
            "\n",
            "That I was the first person to invent the phrase \"lunchtime\" in the form of\n",
            "Expected:The Diogenes Club.\n",
            "------------------------------------------------------------\n",
            "Q36: What is the name of the ancient document recited by Reginald Musgrave?\n",
            "A: Rome, March 3, 1760\n",
            "\n",
            "I have been told that you are very fond of the name of the ancient document recited by the Bishop of Canterbury, called \"The Holy Bible.\" I am aware of no one who has written anything like that, and I am not aware of any other person who has done so. I am sure that this is very worthy of the name.\n",
            "\n",
            "I am pleased to ask the question. What is the name of the ancient document rec\n",
            "Expected:The Musgrave Ritual.\n",
            "------------------------------------------------------------\n",
            "Q37: What injury does Victor Hatherley suffer during his adventure?\n",
            "A: Victor Hatherley's injury is similar to that of some of the other players who have been injured in recent weeks. He has had some setbacks in his recovery, but he has still been able to play this week.\n",
            "\n",
            "What is the prognosis for Victor Hatherley's injury?\n",
            "\n",
            "Victor Hatherley's injury is not expected to affect his performance this week. He will continue to play this week and will be assessed by the team on Tuesday morning.\n",
            "Expected:Loss of a thumb.\n",
            "------------------------------------------------------------\n",
            "Q38: On what moor do the Baskerville events occur?\n",
            "A: The Baskerville events are held at the home of the late Paul G. Baskerville, Jr., where he lived and worked. The event is held on Saturday, July 7th.\n",
            "\n",
            "Is it safe?\n",
            "\n",
            "Yes. The event is free and open to the public.\n",
            "\n",
            "What can I bring?\n",
            "\n",
            "Bring your own picnic lunch, water, and snacks.\n",
            "\n",
            "Where can I park?\n",
            "\n",
            "There are several parking lots located at the corner of\n",
            "Expected:Dartmoor.\n",
            "------------------------------------------------------------\n",
            "Q39: What substance is used to make an animal appear ghostly?\n",
            "A: The answer is very simple.\n",
            "\n",
            "The animal is born with a very special set of cells in its skull. These cells are called pharyngeal epithelium, or pharyngeal cells. They are made up of a special type of white blood cell called a neutrophil.\n",
            "\n",
            "Pharyngeal cells are responsible for the smell of the animal, but they also contain other very important organs such as the liver, lungs, and the blood vessels. The cells in the\n",
            "Expected:Phosphorus.\n",
            "------------------------------------------------------------\n",
            "Q40: In which county is Dartmoor located?\n",
            "A: Dartmoor is located in the County of Essex.\n",
            "\n",
            "Can I speak to a Dartmoor council member?\n",
            "\n",
            "Council members are elected by the people of Dartmoor and are responsible for the management of the Dartmoor Zoo.\n",
            "\n",
            "How do I get involved?\n",
            "\n",
            "The Dartmoor Zoo is a non-profit 501(c)(3) organization and its members are the community.\n",
            "\n",
            "If you are interested in volunteering at the Dartmoor\n",
            "Expected:Devonshire.\n",
            "------------------------------------------------------------\n",
            "Q41: What animal do Holmes and Watson sometimes use to track a scent?\n",
            "A: A \"sniffer dog\" named \"Lucky\" that Holmes and Watson use to sniff out a scent.\n",
            "\n",
            "What was the secret of the \"three-eyed dog\" that Holmes and Watson used to hunt down and kill the monster?\n",
            "\n",
            "The secret of the \"three-eyed dog\" that Holmes and Watson used to hunt down and kill the monster.\n",
            "\n",
            "Why did Holmes and Watson have to hide in the cellar of the house they lived in for so long?\n",
            "Expected:A dog.\n",
            "------------------------------------------------------------\n",
            "Q42: What scientific field is Holmes notably skilled in?\n",
            "A: Holmes is a prolific writer, which has led to speculation that he's a neuroscientist, but the term has been thrown around in connection with Holmes' work in psychology, the paranormal and even science fiction.\n",
            "\n",
            "Holmes was an employee of the British Broadcasting Corporation at the time of his death.\n",
            "\n",
            "The BBC released a statement to CNN about the story.\n",
            "\n",
            "\"We are aware of a story on social media about a professor who has died in the past few days\n",
            "Expected:Chemistry.\n",
            "------------------------------------------------------------\n",
            "Q43: Which police force does Holmes frequently assist?\n",
            "A: \"I don't know, I'm not sure,\" he said. \"I think he's always trying to help anybody he can.\"\n",
            "\n",
            "As for his role as the police chief in the town where he was born, Holmes said he \"was in charge\" of the police department at the time of his arrest.\n",
            "\n",
            "\"I was not there at the time of the arrest,\" Holmes said. \"I was not there at the time of the arrest.\"\n",
            "\n",
            "In the days\n",
            "Expected:Scotland Yard.\n",
            "------------------------------------------------------------\n",
            "Q44: What railway timetable does Holmes often consult?\n",
            "A: Holmes was once a member of the British Army and served as a pilot in World War II.\n",
            "\n",
            "He also studied art and literature.\n",
            "\n",
            "He won the first prize in a competition in 2012 for the best children's book.\n",
            "\n",
            "Holmes was born in Manchester.\n",
            "\n",
            "He was an inspiration to his younger brother Ian, who has been studying art for 18 years.\n",
            "\n",
            "It is not known when Holmes was last seen.\n",
            "\n",
            "Anyone with information is asked to\n",
            "Expected:Bradshaw's.\n",
            "------------------------------------------------------------\n",
            "Q45: What supernatural creature is suspected in a case involving a South American family?\n",
            "A: The body of a woman believed to be missing from the village of Quito, Ecuador, was found by a fisherman on Sunday, and authorities are now searching for her body. The woman was found in a river near Quito, where she had disappeared in October. The victim was described as a white woman with a red face and blue eyes.\n",
            "\n",
            "It's unclear if the woman was killed, but the circumstances of her death are still unknown.\n",
            "\n",
            "It's also unclear what prompted\n",
            "Expected:A vampire.\n",
            "------------------------------------------------------------\n",
            "Q46: What quick message service does Holmes often use?\n",
            "A: \"I am not a real person,\" Holmes says, \"but I do have a lot of emotional stuff going on. I love to cry, and I'm not afraid to cry. I don't like to be angry, and I'm not afraid to be sad. I think that's why I like to talk about what I've been through and what I'm going through, because I feel like if I don't talk about it, people will never know.\"\n",
            "\n",
            "Holmes is\n",
            "Expected:Telegrams.\n",
            "------------------------------------------------------------\n",
            "Q47: What handheld tool does Holmes use to inspect tiny clues?\n",
            "A: The handheld tool is a tiny drill, which Holmes uses to check for explosives or other dangerous materials.\n",
            "\n",
            "\"He's always trying to find something that could possibly be dangerous,\" said Holmes' father, Jerry. \"He's just always looking for a way to do something he shouldn't be doing.\"\n",
            "\n",
            "Holmes is the second person to die after the sheriff's office discovered the bodies of two children who disappeared during a camping trip in April.\n",
            "\n",
            "The bodies of a 13\n",
            "Expected:A magnifying glass.\n",
            "------------------------------------------------------------\n",
            "Q48: In which city do most of Holmes's cases take place?\n",
            "A: The city of Winchester, Virginia.\n",
            "\n",
            "What are the most famous Holmes cases? The case of The Abominable Bride, The Abominable Crows, The Abominable Crows: The True Story of the Murder of Mary Todd Lincoln.\n",
            "\n",
            "What is the most famous Holmes case in American history? The case of The Abominable Bride.\n",
            "\n",
            "What is the most famous Holmes case in England? The Abominable Crows.\n",
            "\n",
            "Who wrote the book The Ab\n",
            "Expected:London.\n",
            "------------------------------------------------------------\n",
            "Q49: After retirement, what hobby does Holmes pursue?\n",
            "A: Holmes: I've got a pet dog, a cat and a few birds, and I've always loved to travel. I've been to more than 30 countries, including Cuba and Italy. I've been to three continents.\n",
            "\n",
            "I'm also a big fan of movies. My favorite is 'Elysium,' and I was also a huge fan of 'Pulp Fiction.' I'm a big fan of 'Pulp Fiction' and 'The Matrix' and 'The Dark\n",
            "Expected:Beekeeping.\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "questions = \"data/questions_sherlock.json\"\n",
        "out_file_name = \"gpt2_answers.txt\"\n",
        "\n",
        "results = test_on_questions(prompt_builder=build_prompt, model_path=model_name, question_file=questions, out_file_name=out_file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choix de max_new_tokens=100\n",
        "\n",
        "Au début, on a testé avec 500 tokens pour laisser le modèle générer des réponses plus longues. Malheureusement, les résultats n'étaient pas satisfaisants. Le modèle se mettait à répéter les mêmes phrases en boucle, comme s'il ne savait plus quoi dire. Ce comportement répétitif rendait les réponses difficiles à exploiter.\n",
        "\n",
        "En plus, les réponses s'éloignaient beaucoup trop du sujet. Le modèle inventait des histoires complètes qui n'avaient rien à voir avec la question posée. Ça produisait beaucoup de texte, mais très peu d'informations pertinentes.\n",
        "\n",
        "**On a donc choisi 100 tokens à la place.** C'est un meilleur compromis parce que:\n",
        "- Les réponses restent courtes et faciles à analyser\n",
        "- Le modèle s'arrête avant de partir hors-sujet\n",
        "- C'est suffisant pour qu'il puisse formuler une réponse complète\n",
        "- Ça correspond mieux aux vraies réponses attendues (qui sont généralement très courtes)\n",
        "\n",
        "Avec 100 tokens, on observe mieux les vraies capacités du modèle sur ce domaine, sans avoir trop de texte inutile à filtrer."
      ],
      "metadata": {
        "id": "uciORCcyHsD-"
      },
      "id": "uciORCcyHsD-"
    },
    {
      "cell_type": "markdown",
      "id": "ef4e39ad2227eab",
      "metadata": {
        "id": "ef4e39ad2227eab"
      },
      "source": [
        "## 4. Analyse des résultats"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe7216ca",
      "metadata": {
        "id": "fe7216ca"
      },
      "source": [
        "### 4.1 Évaluation quantitative (à compléter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "47164745",
      "metadata": {
        "id": "47164745"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def remove_articles(text):\n",
        "    return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "def white_space_fix(text):\n",
        "    return ' '.join(text.split())\n",
        "\n",
        "def remove_punc(text):\n",
        "    exclude = set(string.punctuation)\n",
        "    return ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "def lower(text):\n",
        "    return text.lower()\n",
        "\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Mettre en minuscule et retirer la ponctuation, des déterminants and les espaces.\"\"\"\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "102eef37",
      "metadata": {
        "id": "102eef37"
      },
      "outputs": [],
      "source": [
        "def evaluate_f1(ground_truth, prediction):\n",
        "    \"\"\"Normalise les 2 textes, trouve ce qu'il y a en commun et estime précision, rappel et F1.\"\"\"\n",
        "    prediction_tokens = normalize_answer(prediction).split()\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0.0, 0.0, 0.0\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\n",
        "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return precision, recall, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3a838018",
      "metadata": {
        "id": "3a838018"
      },
      "outputs": [],
      "source": [
        "def evaluation_generation(results):\n",
        "    total_precision = 0\n",
        "    total_recall = 0\n",
        "    total_f1 = 0\n",
        "    num_questions = len(results)\n",
        "\n",
        "    # Calcule les métriques pour chaque question\n",
        "    for i, question, answer, expected_answer in results:\n",
        "        precision, recall, f1 = evaluate_f1(expected_answer, answer)\n",
        "        total_precision += precision\n",
        "        total_recall += recall\n",
        "        total_f1 += f1\n",
        "\n",
        "    # Calcule les moyennes\n",
        "    eval = {\n",
        "        'precision_moyenne': total_precision / num_questions,\n",
        "        'rappel_moyen': total_recall / num_questions,\n",
        "        'f1_moyen': total_f1 / num_questions,\n",
        "        'nombre_questions': num_questions\n",
        "    }\n",
        "\n",
        "    return eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "3802f19e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3802f19e",
        "outputId": "fe9b75a9-eb5d-4dbb-9ba8-83383efe1b06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'precision_moyenne': 0.004469136364648286, 'rappel_moyen': 0.10071428571428571, 'f1_moyen': 0.008330692946605546, 'nombre_questions': 50}\n"
          ]
        }
      ],
      "source": [
        "eval = evaluation_generation(results)\n",
        "print(eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07bd46fb",
      "metadata": {
        "id": "07bd46fb"
      },
      "source": [
        "**Question:** Que pensez-vous de cette évaluation ?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83de8cb0",
      "metadata": {
        "id": "83de8cb0"
      },
      "source": [
        "- Les scores F1, précision et rappel sont extrêmement faibles (F1 = 0.8%), ce qui confirme quantitativement ce que l'analyse qualitative des réponses révèle : GPT-2 échoue presque complètement à répondre correctement aux questions sur Sherlock Holmes.\n",
        "\n",
        "- Le rappel moyen de 10% indique que le modèle capture quelques mots communs des réponses attendues, mais la précision quasi-nulle (0.4%) montre qu'il génère énormément de texte superflu et incorrect.\n",
        "\n",
        "- Le modèle génère du texte grammaticalement correct et apparemment cohérent, mais qui est faux, ce qui illustre le problème d'hallucination des LLMs sans connaissances spécifiques (pour atteindre le nombre de tokens demandés, il rajoute lui-même des questions et invente des réponses).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5288707a",
      "metadata": {
        "id": "5288707a"
      },
      "source": [
        "### 4. Analyse qualitative (à faire)\n",
        "\n",
        "Rédigez **5 à 8 phrases** expliquant ce que vous observez et pourquoi, selon vous, le modèle fournit ce type de réponses.\n",
        "\n",
        "> Cette étape prépare le terrain pour les tâches 3 et 4.\n",
        "> Il est normal que les réponses ne soient pas très bonnes à ce stade. On vous demande d’expliquer **pourquoi**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "958676b4",
      "metadata": {
        "id": "958676b4"
      },
      "source": [
        "Les résultats montrent que GPT-2 génère des réponses complètement incorrectes sur l'univers de Sherlock Holmes. Par exemple, le modèle invente que Holmes et Watson habitent dans un hôtel à Londres au lieu de 221B Baker Street à Londres. Ce problème s'explique par le fait que GPT-2 n'a pas été entraîné spécifiquement sur les textes de Sherlock Holmes. Le modèle essaie quand même de générer des réponses en se basant uniquement sur les structures de phrases qu'il a apprises, ce qui produit du texte qui semble correct grammaticalement mais qui est faux. On observe aussi que le modèle invente beaucoup de détails (noms, dates, lieux) qui semblent vrais mais n'existent pas. Le score F1 très faible de 0.8% confirme cette mauvaise performance. Ces observations montrent qu'un modèle pré-entraîné de façon générale ne peut pas répondre correctement à des questions précises sur un domaine qu'il ne connaît pas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9hZwv-VAL2dm"
      },
      "id": "9hZwv-VAL2dm",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}