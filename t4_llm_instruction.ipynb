{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d53d4c2",
   "metadata": {
    "id": "4d53d4c2"
   },
   "source": [
    "# Tâche 4 : Question-réponse avec affinage par instructions du modèle GPT‑2 pré-entraîné sur Sherlock Holmes\n",
    "\n",
    "**Objectifs**\n",
    "\n",
    "Évaluer la qualité des réponses d’un modèle de langage **pré‑entraîné** (celui de la tâche 3) et affiner par instructions (cette tâche).\n",
    "Dans ce *notebook*, vous faites le post-entraînement du modèle avec des instructions générales indiquant au modèle comment accomplir des tâches simples. Comme pour les tâches 2 et 3, la démarche de test est de construire un *prompt*, de générer des réponses, et d'évaluer qualitativement la pertinence des résultats. Plusieurs de ces fonctions sont rendues disponibles. \n",
    "\n",
    "**Objectifs d’apprentissage**\n",
    "1. Faire le post-entraînement d'un modèle pré‑entraîné avec l'affinage par instructions (*instruction tuning*).\n",
    "2. Comprendre et expliquer les **limites et apports de l'affinage par instructions** d'un modèle.\n",
    "\n",
    "Tout comme dans les tâches 2 et 3, les **questions** pour évaluer le modèle vous sont fournies. Le fichier d'**instructions** pour l'affinage du modèle est également fourni. Vous devez comprendre le format des questions chargées en mémoire. Il est également important de prendre connaissance de la nature des instructions utilisées pour l'affinage. \n",
    "\n",
    "> Il est recommandé de faire ce travail pratique en utilisant une carte graphique GPU compatible avec HuggingFace/Pytorch.\n",
    "> Si votre machine n’en possède pas, vous pouvez utiliser **Google Colab** pour exécuter le *notebook* dans le cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81af0ea3655c4578",
   "metadata": {
    "id": "81af0ea3655c4578"
   },
   "source": [
    "Si nécessaire, installer les *packages* suivant. Si vous exécutez sur Code Colab, ces *packages* devraient déjà être installés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P1jvDsOV7WVW",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T23:15:22.883417Z",
     "start_time": "2025-10-19T23:15:22.872259Z"
    },
    "id": "P1jvDsOV7WVW"
   },
   "outputs": [],
   "source": [
    "#!pip install datasets\n",
    "#!pip install accelerate\n",
    "#!pip install 'transformers[torch]'\n",
    "#!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d460d1d84efc873",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T23:15:23.130682Z",
     "start_time": "2025-10-19T23:15:23.125998Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 5 # il est possible d'ajuster la taille de batch. Les valeurs actuelles utilisent environ 10 Gb\n",
    "max_length = 256 # on réduit le contexte pour sauver du temps, nos exemples ne nécesside pas un plus grand contexte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660a299e09c87174",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T23:15:34.145468Z",
     "start_time": "2025-10-19T23:15:23.155231Z"
    },
    "id": "660a299e09c87174"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import pipeline, Trainer\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b911ebeb",
   "metadata": {},
   "source": [
    "## 1. Chargement du modèle Hugging Face et du tokenizer (à compléter)\n",
    "\n",
    "Complétez le corps de la fonction `load_model(model_path)` afin qu’elle :\n",
    "\n",
    "- charge le **tokenizer** et le **modèle** Hugging Face à partir du chemin `model_path`.\n",
    "- **retourne** le tokenizer comme **première valeur de retour** et le modèle comme **seconde valeur de retour**.\n",
    "\n",
    "On ajoute également des fonctions pour monter les questions en mémoire et pour sauvegarder les réponses dans un fichier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9254d41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T23:15:34.160378Z",
     "start_time": "2025-10-19T23:15:34.155815Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    tokenizer = None  # TODO\n",
    "    model = None  # TODO\n",
    "    \n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c56a1e65ebeb313",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T23:15:34.177800Z",
     "start_time": "2025-10-19T23:15:34.171427Z"
    },
    "id": "4c56a1e65ebeb313"
   },
   "outputs": [],
   "source": [
    "def load_entries(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(f\"Question file must contain a list of objects. Got: {type(data)}\")\n",
    "    return data\n",
    "\n",
    "def save_answers(questions_answers, output_dir, out_file_name, display=True):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with open(os.path.join(output_dir, out_file_name), \"w\", encoding=\"utf-8\") as out:\n",
    "        for index, question, answer, expected_answer in questions_answers:\n",
    "            out.write(f\"Q: {question}\\nA: {answer}\\nExpected:{expected_answer}\\n{'-' * 60}\\n\")\n",
    "            if display:\n",
    "                print(f\"Q{index}: {question}\\nA: {answer}\\nExpected:{expected_answer}\\n{'-' * 60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c168134c",
   "metadata": {},
   "source": [
    "## 2. Fonctions de test question-réponse  (à compléter)\n",
    "\n",
    "La fonction **test_on_questions** est utilisée pour parcourir **toutes les entrées** du fichier de questions afin de produire des réponses générées par le modèle.\n",
    "\n",
    "La génération d'une réponse à une question implique les étapes suivantes (fonction **process_entry** à compléter) : \n",
    "* Construire un prompt à l’aide de la fonction **alpaca_build_prompt** (rendu disponible dans la prochaine section)\n",
    "* Utiliser le modèle (via un pipeline de génération de texte) pour générer une réponse à une question\n",
    "* Retourner la réponse générée par le modèle.  \n",
    "\n",
    "Points importants à souligner: \n",
    "* La fonction *process_entry* doit retourner uniquement la réponse générée par le modèle (sans le prompt).\n",
    "* Il est de votre responsabililté de choisir **les paramètres** du générateur (max_new_tokens, do_sample, temperature, top_k ou top_p). Décrivez ceux que vous avez retenus.\n",
    "\n",
    "> Afin de simplifier le travail, nous avons choisi de ne pas utiliser de *batchs* dans la fonction qui teste les questions.\n",
    "> Vous n'avez pas à prendre en compte le *warning* qui suggère d'utiliser des *datasets*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c52df54",
   "metadata": {},
   "source": [
    "Description des paramètres de génération: \n",
    "(à compléter...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde84d7791669a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T23:15:34.193330Z",
     "start_time": "2025-10-19T23:15:34.188064Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_entry(entry, prompt_builder, generator):\n",
    "    answer = None  # TODO\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4350b250",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T23:15:34.212276Z",
     "start_time": "2025-10-19T23:15:34.205869Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_on_questions(prompt_builder, model_path, question_file, out_file_name, output_dir=\"results\"):\n",
    "    entries = load_entries(question_file)\n",
    "    tokenizer, model = load_model(model_path)\n",
    "    generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "    results = []\n",
    "    for i, entry in enumerate(entries):\n",
    "        answer = process_entry({\"instruction\": entry[\"question\"]}, prompt_builder, generator)\n",
    "        question = entry.get(\"question\", \"\")\n",
    "        expected_answer = entry.get(\"answer\", \"\")\n",
    "        results.append((i, question, answer, expected_answer))\n",
    "    save_answers(results, output_dir, out_file_name, display=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ba4601",
   "metadata": {},
   "source": [
    "## 3. Préparation des données et des prompts pour l'affinage du modèle\n",
    "\n",
    "Le code suivant prépare les ressources nécessaires pour l'affinage du modèle GPT2 pré-entraîné dans la tâche 3 de ce travail.\n",
    "\n",
    "Les étapes sont :\n",
    "* Télécharger le fichier de données Alpaca, le jeu d'instructions utilisé pour l'affinage du modèle . Afin de limiter le temps d'entraînement, on retient seulement les 5000 premières instructions de ce *dataset*. Vous pouvez modifier ce nombre si vous le souhaitez. \n",
    "* Générer un prompt spécifique à Alpaca.\n",
    "\n",
    "On rend disponible tout ce qui est nécessaire pour ces 2 étapes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b0e8835a7572",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T23:15:35.426389Z",
     "start_time": "2025-10-19T23:15:34.222036Z"
    },
    "id": "4a0b0e8835a7572"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "alpaca_url = \"https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/refs/heads/main/alpaca_data.json\"\n",
    "\n",
    "def load_or_download_instruct_dataset_file(data_url, file_path, count=-1):\n",
    "    with urllib.request.urlopen(data_url) as response:\n",
    "        raw_data = response.read().decode(\"utf-8\")\n",
    "        data = json.loads(raw_data)\n",
    "    if count > 0 and count <= len(data):\n",
    "        data = data[:count]\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=2)\n",
    "\n",
    "instructions_fn = \"data/alpaca_data.json\"  # Fichier où sont enregistrées les instructions d'affinage du modèle\n",
    "nb_instructions = 5000  # Ce nombre peut-être modifié\n",
    "load_or_download_instruct_dataset_file(data_url=alpaca_url, count=nb_instructions, file_path=instructions_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ac4464a8f26ba6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T23:15:35.442369Z",
     "start_time": "2025-10-19T23:15:35.437440Z"
    },
    "id": "27ac4464a8f26ba6"
   },
   "outputs": [],
   "source": [
    "def alpaca_build_prompt(ex):\n",
    "    instruction = ex.get(\"instruction\", \"\")\n",
    "    input = ex.get(\"input\", \"\").strip()\n",
    "    header = \"Below is an instruction that describes a task\"\n",
    "    if input:\n",
    "        header += \", paired with an input\"\n",
    "    return (\n",
    "        f\"{header}.\\n\"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        f\"### Instruction:\\n{instruction}\\n\\n\"\n",
    "        + (f\"### Input:\\n{input}\\n\\n\" if input else \"\")\n",
    "        + \"### Response:\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb13219",
   "metadata": {},
   "source": [
    "## 4. Affinage du modèle (à compléter)\n",
    "\n",
    "Complétez le code suivant pour affiner le modèle GPT2 préentraîné et sauvegardé dans la tâche 3 de ce travail.\n",
    "\n",
    "Les étapes à suivre sont de :\n",
    "* Monter en mémoire le modèle pré-entraîné à la tâche 3 et son tokeniseur \n",
    "* Monter le jeu d'instructions pour l'affinage du modèle et créer un *dataset* avec ces données.\n",
    "* Tokeniser ce *dataset* d'instructions\n",
    "* Faire l'entraînement du modèle sur le *dataset* avec la classe ***Trainer*** de Hugging Face\n",
    "* Faire la sauvegarde du nouveau modèle dans un répertoire (voir *model_path*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c5593c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T23:15:35.743886Z",
     "start_time": "2025-10-19T23:15:35.455611Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"gpt2-sherlock-lm\" # Répertoire du modèle construit durant la tâche 3\n",
    "tokenizer, model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cdc69e",
   "metadata": {},
   "source": [
    "Création du *dataset* d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd049187",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T23:15:36.478897Z",
     "start_time": "2025-10-19T23:15:35.769817Z"
    }
   },
   "outputs": [],
   "source": [
    "instructions_fn = \"data/alpaca_data.json\"  # Fichier qui contient les instructions d'affinage\n",
    "dataset = None  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba80b0f8",
   "metadata": {},
   "source": [
    "Tokénisation du *dataset* d'entraînement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738415a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T23:15:36.506618Z",
     "start_time": "2025-10-19T23:15:36.500252Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d42771",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T23:15:40.719083Z",
     "start_time": "2025-10-19T23:15:36.530401Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = None  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23aca5c",
   "metadata": {},
   "source": [
    "Ajouter dans ces cellules tout le code dont vous avez besoin pour faire l'affinage du modèle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2732703a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T23:15:42.892925Z",
     "start_time": "2025-10-19T23:15:40.722063Z"
    }
   },
   "outputs": [],
   "source": [
    "instruct_model_path = \"gpt2-sherlock-instruct\" # Répertoire où sauvegarder le nouveau modèle et le tokenizer \n",
    "\n",
    "trainer = None  # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e38be4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T23:15:42.931252Z",
     "start_time": "2025-10-19T23:15:42.927004Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9f67bf566a5b28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T23:22:22.666862Z",
     "start_time": "2025-10-19T23:15:42.951795Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416,
     "referenced_widgets": [
      "9cf8f9c87d224dc0bdeaa9788b5d0880",
      "177cb70e811744d9b807a50ab8906835",
      "7f97d6edeeb740899fd8b58879030fe4",
      "879a8f1045ab4d77adaa992759dc7264",
      "fe8e9dc94d174a79aa20a2121fe0dcd6",
      "bfd3a46cec604b58994c9445a3abd3b9",
      "6fb270e11547433ea37333150983834d",
      "b4c6536d6c2945d7bc5387bc4ed7c8fa",
      "64203e620c994f50bb50435f161d641b",
      "21c87467c9c9485aa5f073ae5e2db788",
      "f87b1e94bff249fd954354f5c80b91e8"
     ]
    },
    "id": "3e9f67bf566a5b28",
    "outputId": "5622b47a-c0eb-44b2-cc6f-b94a3d35fc0f"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993e9d7f",
   "metadata": {},
   "source": [
    "Pour conclure cette section, sauvegardez le nouveau modèle et le tokenizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e551d44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T23:22:25.212503Z",
     "start_time": "2025-10-19T23:22:22.748102Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model(instruct_model_path)  \n",
    "tokenizer.save_pretrained(instruct_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc459e7a",
   "metadata": {},
   "source": [
    "## 5. Génération des réponses pour les questions de Sherlock Holmes\n",
    "\n",
    "Exécutez la cellule suivante pour générer, avec le modèle affiné, les réponses aux questions de test.\n",
    "Le temps d’exécution devrait se situer entre **5 et 10 minutes** si vous utilisez **Google Colab** avec un GPU.\n",
    "\n",
    "Note : N'oubliez pas d'ajouter le fichier de réponses générées par le modèle (voir *out_file_name*) dans votre remise du travail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_ntrtd3jWnhs",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-10-19T23:22:25.238643Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "_ntrtd3jWnhs",
    "jupyter": {
     "is_executing": true
    },
    "outputId": "f328f631-10a2-415d-f5fb-63fa36e2a282"
   },
   "outputs": [],
   "source": [
    "questions_fn = \"data/questions_sherlock.json\"\n",
    "out_file_name = \"instruct_gpt2_answers.txt\"\n",
    "\n",
    "results = test_on_questions(prompt_builder=alpaca_build_prompt, model_path=instruct_model_path, question_file=questions_fn, out_file_name=out_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df7d2c0",
   "metadata": {},
   "source": [
    " ## 6. Analyse des résultats \n",
    " \n",
    " ### 6.1 Évaluation quantitative (à compléter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d105903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def remove_articles(text):\n",
    "    return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "def white_space_fix(text):\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "def remove_punc(text):\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def normalize_answer(s):\n",
    "    \"\"\"Mettre en minuscule et retirer la ponctuation, des déterminants and les espaces.\"\"\"\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c884b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_f1(ground_truth, prediction):\n",
    "    \"\"\"Normalise les 2 textes, trouve ce qu'il y a en commun et estime précision, rappel et F1.\"\"\"\n",
    "    prediction_tokens = normalize_answer(prediction).split()\n",
    "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fe1607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_generation(results): \n",
    "    # TODO\n",
    "    return eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd0f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = evaluation_generation(results)\n",
    "print(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521bcbe2",
   "metadata": {},
   "source": [
    "**Question :** Que pensez-vous de cette évaluation ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f20fe54",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09d00e33",
   "metadata": {},
   "source": [
    "### 6.2 Analyse qualitative (à faire) \n",
    "\n",
    "Faites l'analyse des réponses de ce modèle. Présentez vos observations par rapport aux réponses obtenus des modèles des tâches 2 et 3. \n",
    "\n",
    "Expliquez ce que vous retenez des 3 dernières tâches sur le pré-entraînement et le post-entraînement du modèle GPT-2. \n",
    "\n",
    "Vous pouvez ajouter des cellules au besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bab549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02d5730a3b824b9488ac965c8cf03975": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63855c1f3e434b5e912d16e9fcca3c7d",
      "placeholder": "​",
      "style": "IPY_MODEL_0e00d0317d9e4fb595d9ffd116492957",
      "value": "Map: 100%"
     }
    },
    "0e00d0317d9e4fb595d9ffd116492957": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "177cb70e811744d9b807a50ab8906835": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bfd3a46cec604b58994c9445a3abd3b9",
      "placeholder": "​",
      "style": "IPY_MODEL_6fb270e11547433ea37333150983834d",
      "value": "Map: 100%"
     }
    },
    "1852bde0ee79493ba8adb5c6e80c0e26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_02d5730a3b824b9488ac965c8cf03975",
       "IPY_MODEL_246410304692490a9c75f15cccad2ca7",
       "IPY_MODEL_e49397f3a86c4a628484195f1c8f35e5"
      ],
      "layout": "IPY_MODEL_1993b6bf7e8540ba960cd5a99dfacc02"
     }
    },
    "1993b6bf7e8540ba960cd5a99dfacc02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21c87467c9c9485aa5f073ae5e2db788": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "246410304692490a9c75f15cccad2ca7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c2556b64a7b4c6d999ccc5fd5095c55",
      "max": 11055,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b8020e8db2f14c8ba90ec9f1a9ce25de",
      "value": 11055
     }
    },
    "5c2556b64a7b4c6d999ccc5fd5095c55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63855c1f3e434b5e912d16e9fcca3c7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64203e620c994f50bb50435f161d641b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6fb270e11547433ea37333150983834d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7c18198369c04dd8ae24f9ac7eacc139": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f97d6edeeb740899fd8b58879030fe4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4c6536d6c2945d7bc5387bc4ed7c8fa",
      "max": 52002,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_64203e620c994f50bb50435f161d641b",
      "value": 52002
     }
    },
    "879a8f1045ab4d77adaa992759dc7264": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21c87467c9c9485aa5f073ae5e2db788",
      "placeholder": "​",
      "style": "IPY_MODEL_f87b1e94bff249fd954354f5c80b91e8",
      "value": " 52002/52002 [01:11&lt;00:00, 1158.09 examples/s]"
     }
    },
    "9cf8f9c87d224dc0bdeaa9788b5d0880": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_177cb70e811744d9b807a50ab8906835",
       "IPY_MODEL_7f97d6edeeb740899fd8b58879030fe4",
       "IPY_MODEL_879a8f1045ab4d77adaa992759dc7264"
      ],
      "layout": "IPY_MODEL_fe8e9dc94d174a79aa20a2121fe0dcd6"
     }
    },
    "b4c6536d6c2945d7bc5387bc4ed7c8fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8020e8db2f14c8ba90ec9f1a9ce25de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bfd3a46cec604b58994c9445a3abd3b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cedc0966f194417d94db80646792daf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e49397f3a86c4a628484195f1c8f35e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c18198369c04dd8ae24f9ac7eacc139",
      "placeholder": "​",
      "style": "IPY_MODEL_cedc0966f194417d94db80646792daf8",
      "value": " 11055/11055 [00:06&lt;00:00, 1944.70 examples/s]"
     }
    },
    "f87b1e94bff249fd954354f5c80b91e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe8e9dc94d174a79aa20a2121fe0dcd6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
